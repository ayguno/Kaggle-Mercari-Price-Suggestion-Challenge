{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and processing the data sets\n",
    "\n",
    "Let's start with loading the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '.git',\n",
       " '.ipynb_checkpoints',\n",
       " '.Rapp.history',\n",
       " '.RDataTmp',\n",
       " '.Rhistory',\n",
       " 'GBM.rds',\n",
       " 'GBM.stack.rds',\n",
       " 'Kaggle Mercari Price Suggestion Challenge IPython Kernel.ipynb',\n",
       " 'KaggleMercariPriceSuggestionChallengeKernel.Rmd',\n",
       " 'Mercari Price Suggestion Challenge | Kaggle.pdf',\n",
       " 'merged_table.rds',\n",
       " 'mini_subtrain.rds',\n",
       " 'mini_subtrain_locked.rds',\n",
       " 'mini_train.rds',\n",
       " 'new_stack_set.rds',\n",
       " 'new_stack_set2.rds',\n",
       " 'RF.BC.rds',\n",
       " 'RF.rds',\n",
       " 'RF.stack.rds',\n",
       " 'RF.stack2nd.rds',\n",
       " 'sample_submission.csv',\n",
       " 'sample_submission.csv.7z',\n",
       " 'second.stack.set.rds',\n",
       " 'subtrain.rds',\n",
       " 'subtrain_locked.rds',\n",
       " 'SVM.rds',\n",
       " 'SVM.stack.rds',\n",
       " 'test.csv',\n",
       " 'test.rds',\n",
       " 'test.tsv.7z',\n",
       " 'test_locked.rds',\n",
       " 'train.csv',\n",
       " 'train.rds',\n",
       " 'train.tsv.7z',\n",
       " 'v.txt',\n",
       " 'validation.rds',\n",
       " 'validation_locked.rds',\n",
       " 'X_holdout.csv',\n",
       " 'X_train.csv',\n",
       " 'xGBM.BC.rds',\n",
       " 'xGBM.BC2.rds',\n",
       " 'xGBM.rds',\n",
       " 'xGBM.stack.rds',\n",
       " 'xGBM.stack2nd.rds',\n",
       " 'y_holdout.csv',\n",
       " 'y_train.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>Home/Home Décor/Home Décor Accents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "3         3                Leather Horse Statues                  1   \n",
       "4         4                 24K GOLD plated rose                  1   \n",
       "\n",
       "                                       category_name brand_name  price  \\\n",
       "0                                  Men/Tops/T-shirts        NaN   10.0   \n",
       "1  Electronics/Computers & Tablets/Components & P...      Razer   52.0   \n",
       "2                        Women/Tops & Blouses/Blouse     Target   10.0   \n",
       "3                 Home/Home Décor/Home Décor Accents        NaN   35.0   \n",
       "4                            Women/Jewelry/Necklaces        NaN   44.0   \n",
       "\n",
       "   shipping                                   item_description  \n",
       "0         1                                 No description yet  \n",
       "1         0  This keyboard is in great condition and works ...  \n",
       "2         1  Adorable top with a hint of lace and a key hol...  \n",
       "3         1  New with tags. Leather horses. Retail for [rm]...  \n",
       "4         0          Complete with certificate of authenticity  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1482535 entries, 0 to 1482534\n",
      "Data columns (total 8 columns):\n",
      "train_id             1482535 non-null int64\n",
      "name                 1482535 non-null object\n",
      "item_condition_id    1482535 non-null int64\n",
      "category_name        1476208 non-null object\n",
      "brand_name           849853 non-null object\n",
      "price                1482535 non-null float64\n",
      "shipping             1482535 non-null int64\n",
      "item_description     1482531 non-null object\n",
      "dtypes: float64(1), int64(3), object(4)\n",
      "memory usage: 90.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's remove the train_id from the training set, and map the numeric and character variables to being with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>Home/Home Décor/Home Décor Accents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  item_condition_id  \\\n",
       "0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2                       AVA-VIV Blouse                  1   \n",
       "3                Leather Horse Statues                  1   \n",
       "4                 24K GOLD plated rose                  1   \n",
       "\n",
       "                                       category_name brand_name  price  \\\n",
       "0                                  Men/Tops/T-shirts        NaN   10.0   \n",
       "1  Electronics/Computers & Tablets/Components & P...      Razer   52.0   \n",
       "2                        Women/Tops & Blouses/Blouse     Target   10.0   \n",
       "3                 Home/Home Décor/Home Décor Accents        NaN   35.0   \n",
       "4                            Women/Jewelry/Necklaces        NaN   44.0   \n",
       "\n",
       "   shipping                                   item_description  \n",
       "0         1                                 No description yet  \n",
       "1         0  This keyboard is in great condition and works ...  \n",
       "2         1  Adorable top with a hint of lace and a key hol...  \n",
       "3         1  New with tags. Leather horses. Retail for [rm]...  \n",
       "4         0          Complete with certificate of authenticity  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop(\"train_id\",axis = 1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1482535 entries, 0 to 1482534\n",
      "Data columns (total 7 columns):\n",
      "name                 1482535 non-null object\n",
      "item_condition_id    1482535 non-null int64\n",
      "category_name        1476208 non-null object\n",
      "brand_name           849853 non-null object\n",
      "price                1482535 non-null float64\n",
      "shipping             1482535 non-null int64\n",
      "item_description     1482531 non-null object\n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 79.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Numeric_features_select = np.logical_or((pd.Series(train.dtypes)) == \"int64\",(pd.Series(train.dtypes) == \"float64\")).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Numeric_features = pd.Series(train.columns)[Numeric_features_select].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "Numeric_features.remove('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_condition_id', 'shipping']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_features = pd.Series(train.columns)[np.logical_not(Numeric_features_select)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'category_name', 'brand_name', 'item_description']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model evaluation will be based on the log of the target variable price, we convert it at this stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.price = pd.Series(np.log(train.price + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>3.970292</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>Home/Home Décor/Home Décor Accents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.806662</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  item_condition_id  \\\n",
       "0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2                       AVA-VIV Blouse                  1   \n",
       "3                Leather Horse Statues                  1   \n",
       "4                 24K GOLD plated rose                  1   \n",
       "\n",
       "                                       category_name brand_name     price  \\\n",
       "0                                  Men/Tops/T-shirts        NaN  2.397895   \n",
       "1  Electronics/Computers & Tablets/Components & P...      Razer  3.970292   \n",
       "2                        Women/Tops & Blouses/Blouse     Target  2.397895   \n",
       "3                 Home/Home Décor/Home Décor Accents        NaN  3.583519   \n",
       "4                            Women/Jewelry/Necklaces        NaN  3.806662   \n",
       "\n",
       "   shipping                                   item_description  \n",
       "0         1                                 No description yet  \n",
       "1         0  This keyboard is in great condition and works ...  \n",
       "2         1  Adorable top with a hint of lace and a key hol...  \n",
       "3         1  New with tags. Leather horses. Retail for [rm]...  \n",
       "4         0          Complete with certificate of authenticity  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to split the training data set into training and holdout sets in order to start building our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train.drop(\"price\", axis = 1)\n",
    "y = train.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_holdout,y_train,y_holdout = train_test_split(X,y,test_size = 0.4, random_state = 425)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889521, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(593014, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889521,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(593014,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_holdout.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, let's lockdown and save the datasets on which we will train and validate our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8a103d2ed782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mX_holdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_holdout.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y_train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train.to_csv(\"X_train.csv\",index=False)\n",
    "X_holdout.to_csv(\"X_holdout.csv\", index = False)\n",
    "y_train.to_csv(\"y_train.csv\", index= False)\n",
    "y_holdout.to_csv(\"y_holdout.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the pickled feature names\n",
    "import pickle\n",
    "with open(\"Numeric_features.pkl\", 'wb') as f:\n",
    "    pickle.dump(Numeric_features,f)\n",
    "f.close()\n",
    "\n",
    "with open(\"Text_features.pkl\", 'wb') as f:\n",
    "    pickle.dump(Text_features,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing and model training pipeline\n",
    "\n",
    "At this stage we will make high-level design for our data processing and model training pipeline. At minimum, our pipeline will need to include the following steps:\n",
    "\n",
    "1. We need to process text and numeric features seperately, then combine them using FeatureUnion()\n",
    "\n",
    "    2. Text  subpipeline should include:\n",
    "        - A function that will merge all text in a given row to make it ready for tokenization. \n",
    "            - This function should take care of converting missing values to empty strings. \n",
    "            - It should also convert the text to lowercase.\n",
    "        - We should remove common stop words and perform text stemming\n",
    "        - We should tokenize using alphanumeric characters only (white space + punctuation are used as delimiters)\n",
    "        - We try to include up to 3-grams\n",
    "\n",
    "    3. Numeric subpipeline should include:\n",
    "        - An imputation step to fill any missing values using mean of the column\n",
    "        - A scaling step that will scale the numeric values between -1 and 1\n",
    "        \n",
    "4. After merging the numeric and text features we will add the following common steps:\n",
    "    5. Adding interaction terms\n",
    "    6. Perform a simple feature selection using F-regression method we learned\n",
    "    7. We will try to include a hashing step to improve computational efficiency\n",
    "7. Finally, we will put a model training step, we will start with a regularized linear regression.\n",
    "\n",
    "Once our pipeline is ready, our goals will be:\n",
    "\n",
    "- to get some idea about the initial performance of the pipeline using the simple model in holdout set, using default hyperparameters\n",
    "- then try to perform hyperparameter tuning (such as GridSearchCV or RandomSearchCV) to see if we can come up with a better model. \n",
    "- save the model that has the best overall performance ( based on rmse using holdout set)\n",
    "\n",
    "Finally, we will repeat these steps using the same pipeline, but changing model structure to train:\n",
    "\n",
    "- Elastic Net model\n",
    "- Support vector machines\n",
    "- RandomForest regression\n",
    "- Gradient boosting\n",
    "\n",
    "After these steps, we will explore ensembling these models to see if we can get a better model.\n",
    "\n",
    "At the end of this exercise, we expect to get more competent on:\n",
    "\n",
    "1. experiencing developing sklearn pipelines and incorporating custom functions\n",
    "2. basic NLP tasks we can perform with our current knowledge\n",
    "3. developing an intuition about the performance of different models, \n",
    "4. experiencing the sklearn API for hyperparameter tuning using important algorithms \n",
    "\n",
    "Finally, we will try to use the same sets to train Deep Neural Networks to see how they compare to the performance of shallow learning approaches.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Re-read the training data\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\", header=None, names= [\"price\"])\n",
    "\n",
    "y_train = y_train.price.values\n",
    "\n",
    "# Re-read the pickled feature names\n",
    "import pickle\n",
    "with open(\"Numeric_features.pkl\", 'rb') as f:\n",
    "    Numeric_features = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "with open(\"Text_features.pkl\", 'rb') as f:\n",
    "    Text_features = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A custom function for text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_text_processer(df,text_columns = Text_features):\n",
    "    \"\"\"\"A function that will merge/join all text in a given row to make it ready for tokenization. \n",
    "    - This function should take care of converting missing values to empty strings. \n",
    "    - It should also convert the text to lowercase.\n",
    "    df= pandas dataframe\n",
    "    text_columns = names of the text features in df\n",
    "    \"\"\" \n",
    "    # Select only non-text columns that are in the df\n",
    "    text_data = df[text_columns]\n",
    "    \n",
    "    # Fill the missing values in text_data using empty strings\n",
    "    text_data.fillna(\"\",inplace=True)\n",
    "    \n",
    "    # Join all the strings in a given row to make a vector\n",
    "    text_vector = text_data.apply(lambda x: \" \".join(x), axis = 1)\n",
    "    \n",
    "    # Convert all the text to lowercase and return as pd.Series object to enter the tokenization pipeline\n",
    "    return text_vector.apply(lambda x: x.lower())   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model training pipeline\n",
    "\n",
    "We will start by loading the necessary functions from sklearn submodules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler, Imputer, FunctionTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we build two utility functions to parse numeric and text data, and wrap them using FunctionTransformer, so that they can be integrated into a sklearn pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_numeric_data = FunctionTransformer(func = lambda x: x[Numeric_features], validate=False) #Note x is by default the tensor that contains all features\n",
    "get_text_data = FunctionTransformer(column_text_processer,validate=False) # Note how we avoid putting any arguments into column_text_processer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to create our regex token pattern to use in CountVectorizer. CountVectorizer will use this regex pattern to create tokens and n-grams we specified. It will automatically convert these into dummy features and stores in the form of a sparsemartix. Note that we will use HashingVectorizer to improve computational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'   #Note this regex will match either a whitespace or a punctuation to tokenize the string vector on these preferences  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to redefine the default feature selection function for regression to properly place into our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_regression(X,Y):\n",
    "    import sklearn\n",
    "    return sklearn.feature_selection.f_regression(X,Y,center = False) # default is center = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start building the actual pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl1 = Pipeline([\n",
    "    (\"union\",FeatureUnion(        #Note that FeatureUnion() accepts list of tuples, the first half of each tuple is the name of the transformer\n",
    "        transformer_list = [\n",
    "            (\"numeric_subpipeline\", Pipeline([        #Note we have subpipeline branches inside the main pipeline\n",
    "                \n",
    "                (\"parser\",get_numeric_data), # Step1: parse the numeric data (note how we avoid () when using FunctionTransformer objects)\n",
    "                (\"imputer\",Imputer()), # Step2: impute missing values\n",
    "            \n",
    "            ])), # Branching point of the FeatureUnion\n",
    "            \n",
    "            (\"text_subpipeline\",Pipeline([\n",
    "            \n",
    "                (\"parser\",get_text_data), # Step1: parse the text data \n",
    "                (\"tokenizer\",HashingVectorizer(token_pattern= TOKENS_ALPHANUMERIC,\n",
    "                                             stop_words = \"english\",# We will remove English stop words before tokenization\n",
    "                                             ngram_range = (1,3),\n",
    "                                             non_negative=True, norm=None, binary=False  \n",
    "                                            )), # Step2: use CountVectorizer for automated tokenization and feature extraction\n",
    "                                            ('dim_red', SelectKBest(f_regression, 300)) # Step3: use dimension reduction to select 300 best features\n",
    "                \n",
    "            ]))\n",
    "        ]\n",
    "    \n",
    "    )),# Branching point to the main pipeline: at this point all fearures are numeric\n",
    "    \n",
    "    #(\"int\", SparseInteractions(degree=2)), # Add polynomial interaction terms :POSTPONED\n",
    "    (\"scaler\",MaxAbsScaler()), # Scale the features\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:279: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= row_norms(X.T)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "# We fit_transform X outside of the pipeline to obtain transformed X for hyperparameter search, \n",
    "# since transformation step takes long time and we want to avoid repeating everytime \n",
    "X_train_transformed = pl1.fit_transform(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We start with ridge regression\n",
    "model1 = Ridge(alpha=0.5)\n",
    "model1.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model1.predict(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63839928042826788"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(y_train,y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD9CAYAAACcJ53WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x152cfdeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(y_pred1,y_train, s = 2, c = \"r\", alpha = 0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple pipeline already looks very promising!\n",
    "\n",
    "## Ridge Hyperparameter tuning\n",
    "\n",
    "First, we compile the data loading, utility functions and pipeline steps for easy starting up later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#############################################################################\n",
    "# Re-read the training data\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\", header=None, names= [\"price\"])\n",
    "\n",
    "y_train = y_train.price.values\n",
    "\n",
    "#############################################################################\n",
    "# Re-read the pickled feature names\n",
    "import pickle\n",
    "with open(\"Numeric_features.pkl\", 'rb') as f:\n",
    "    Numeric_features = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "with open(\"Text_features.pkl\", 'rb') as f:\n",
    "    Text_features = pickle.load(f)\n",
    "f.close()\n",
    "#############################################################################\n",
    "\n",
    "def column_text_processer(df,text_columns = Text_features):\n",
    "    \"\"\"\"A function that will merge/join all text in a given row to make it ready for tokenization. \n",
    "    - This function should take care of converting missing values to empty strings. \n",
    "    - It should also convert the text to lowercase.\n",
    "    df= pandas dataframe\n",
    "    text_columns = names of the text features in df\n",
    "    \"\"\" \n",
    "    # Select only non-text columns that are in the df\n",
    "    text_data = df[text_columns]\n",
    "    \n",
    "    # Fill the missing values in text_data using empty strings\n",
    "    text_data.fillna(\"\",inplace=True)\n",
    "    \n",
    "    # Join all the strings in a given row to make a vector\n",
    "    text_vector = text_data.apply(lambda x: \" \".join(x), axis = 1)\n",
    "    \n",
    "    # Convert all the text to lowercase and return as pd.Series object to enter the tokenization pipeline\n",
    "    return text_vector.apply(lambda x: x.lower())  \n",
    "\n",
    "#############################################################################\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler, Imputer, FunctionTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "#############################################################################\n",
    "# Utility functions to parse text and numeric features\n",
    "get_numeric_data = FunctionTransformer(func = lambda x: x[Numeric_features], validate=False) #Note x is by default the tensor that contains all features\n",
    "get_text_data = FunctionTransformer(column_text_processer,validate=False) # Note how we avoid putting any arguments into column_text_processer\n",
    "#############################################################################\n",
    "\n",
    "#############################################################################\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'   #Note this regex will match either a whitespace or a punctuation to tokenize the string vector on these preferences  \n",
    "\n",
    "#############################################################################\n",
    "# Define f_regression for feature selection with center = True default\n",
    "def f_regression(X,Y):\n",
    "    import sklearn\n",
    "    return sklearn.feature_selection.f_regression(X,Y,center = False) # default is center = True\n",
    "\n",
    "#############################################################################\n",
    "# Prepare the actual pipeline:\n",
    "\n",
    "pl1 = Pipeline([\n",
    "    (\"union\",FeatureUnion(        #Note that FeatureUnion() accepts list of tuples, the first half of each tuple is the name of the transformer\n",
    "        transformer_list = [\n",
    "            (\"numeric_subpipeline\", Pipeline([        #Note we have subpipeline branches inside the main pipeline\n",
    "                \n",
    "                (\"parser\",get_numeric_data), # Step1: parse the numeric data (note how we avoid () when using FunctionTransformer objects)\n",
    "                (\"imputer\",Imputer()), # Step2: impute missing values\n",
    "            \n",
    "            ])), # Branching point of the FeatureUnion\n",
    "            \n",
    "            (\"text_subpipeline\",Pipeline([\n",
    "            \n",
    "                (\"parser\",get_text_data), # Step1: parse the text data \n",
    "                (\"tokenizer\",HashingVectorizer(token_pattern= TOKENS_ALPHANUMERIC,\n",
    "                                             stop_words = \"english\",# We will remove English stop words before tokenization\n",
    "                                             ngram_range = (1,3),\n",
    "                                             non_negative=True, norm=None, binary=False  \n",
    "                                            )), # Step2: use CountVectorizer for automated tokenization and feature extraction\n",
    "                                            ('dim_red', SelectKBest(f_regression, 300)) # Step3: use dimension reduction to select 300 best features\n",
    "                \n",
    "            ]))\n",
    "        ]\n",
    "    \n",
    "    )),# Branching point to the main pipeline: at this point all fearures are numeric\n",
    "    \n",
    "    #(\"int\", SparseInteractions(degree=2)), # Add polynomial interaction terms :POSTPONED\n",
    "    (\"scaler\",MaxAbsScaler()), # Scale the features\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-fb5db04dc556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# We fit_transform X outside of the pipeline to obtain transformed X for hyperparameter search,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# since transformation step takes long time and we want to avoid repeating everytime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \"\"\"\n\u001b[1;32m    280\u001b[0m         \u001b[0mlast_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    212\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                        **fit_params):\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    737\u001b[0m             delayed(_fit_transform_one)(trans, weight, X, y,\n\u001b[1;32m    738\u001b[0m                                         **fit_params)\n\u001b[0;32m--> 739\u001b[0;31m             for name, trans, weight in self._iter())\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                        **fit_params):\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlast_step\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mscore_func_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_func_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_func_ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-ef70ab9d7316>\u001b[0m in \u001b[0;36mf_regression\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# default is center = True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m#############################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py\u001b[0m in \u001b[0;36mf_regression\u001b[0;34m(X, y, center)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;31m# compute the correlation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0mcorr\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mX_norms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0mcorr\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \"\"\"\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdense_output\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"toarray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__rmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;31m#####################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;31m# Fast path for the most common case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_mul_vector\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;31m# csr_matvec or csc_matvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_matvec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# We fit_transform X outside of the pipeline to obtain transformed X for hyperparameter search, \n",
    "# since transformation step takes long time and we want to avoid repeating everytime \n",
    "X_train_transformed = pl1.fit_transform(X_train,y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start hyperparameter optimization. Let's first start by looking into the tunable hyperparameters in ridge model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.5,\n",
       " 'copy_X': True,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': None,\n",
       " 'normalize': False,\n",
       " 'random_state': None,\n",
       " 'solver': 'auto',\n",
       " 'tol': 0.001}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking into parameters of our first estimator:\n",
    "\n",
    "model1.get_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plan to start by tuning the alpha, which is the most important hyperparameter that defines the strength of regularization. A sensible value is between 1 and 0. We will use Exhaustive search over specified parameter values for an estimator, which is performed by **GridSearchCV** using 5 fold cross-validation. Since we only perform search in one hyperparameter, this is a one-dimensional grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.94736842,  0.89473684,  0.84210526,  0.78947368,\n",
       "        0.73684211,  0.68421053,  0.63157895,  0.57894737,  0.52631579,\n",
       "        0.47368421,  0.42105263,  0.36842105,  0.31578947,  0.26315789,\n",
       "        0.21052632,  0.15789474,  0.10526316,  0.05263158,  0.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We prepare 20 grids of alpha in a linear space\n",
    "alpha_space = np.linspace(1,0,20)\n",
    "alpha_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GridSearchCV in module sklearn.model_selection._search:\n",
      "\n",
      "class GridSearchCV(BaseSearchCV)\n",
      " |  Exhaustive search over specified parameter values for an estimator.\n",
      " |  \n",
      " |  Important members are fit, predict.\n",
      " |  \n",
      " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      " |  It also implements \"predict\", \"predict_proba\", \"decision_function\",\n",
      " |  \"transform\" and \"inverse_transform\" if they are implemented in the\n",
      " |  estimator used.\n",
      " |  \n",
      " |  The parameters of the estimator used to apply these methods are optimized\n",
      " |  by cross-validated grid-search over a parameter grid.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <grid_search>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object.\n",
      " |      This is assumed to implement the scikit-learn estimator interface.\n",
      " |      Either estimator needs to provide a ``score`` function,\n",
      " |      or ``scoring`` must be passed.\n",
      " |  \n",
      " |  param_grid : dict or list of dictionaries\n",
      " |      Dictionary with parameters names (string) as keys and lists of\n",
      " |      parameter settings to try as values, or a list of such\n",
      " |      dictionaries, in which case the grids spanned by each dictionary\n",
      " |      in the list are explored. This enables searching over any sequence\n",
      " |      of parameter settings.\n",
      " |  \n",
      " |  scoring : string, callable or None, default=None\n",
      " |      A string (see model evaluation documentation) or\n",
      " |      a scorer callable object / function with signature\n",
      " |      ``scorer(estimator, X, y)``.\n",
      " |      If ``None``, the ``score`` method of the estimator is used.\n",
      " |  \n",
      " |  fit_params : dict, optional\n",
      " |      Parameters to pass to the fit method.\n",
      " |  \n",
      " |  n_jobs : int, default=1\n",
      " |      Number of jobs to run in parallel.\n",
      " |  \n",
      " |  pre_dispatch : int, or string, optional\n",
      " |      Controls the number of jobs that get dispatched during parallel\n",
      " |      execution. Reducing this number can be useful to avoid an\n",
      " |      explosion of memory consumption when more jobs get dispatched\n",
      " |      than CPUs can process. This parameter can be:\n",
      " |  \n",
      " |          - None, in which case all the jobs are immediately\n",
      " |            created and spawned. Use this for lightweight and\n",
      " |            fast-running jobs, to avoid delays due to on-demand\n",
      " |            spawning of the jobs\n",
      " |  \n",
      " |          - An int, giving the exact number of total jobs that are\n",
      " |            spawned\n",
      " |  \n",
      " |          - A string, giving an expression as a function of n_jobs,\n",
      " |            as in '2*n_jobs'\n",
      " |  \n",
      " |  iid : boolean, default=True\n",
      " |      If True, the data is assumed to be identically distributed across\n",
      " |      the folds, and the loss minimized is the total loss per sample,\n",
      " |      and not the mean loss across the folds.\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, optional\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |        - None, to use the default 3-fold cross validation,\n",
      " |        - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      " |        - An object to be used as a cross-validation generator.\n",
      " |        - An iterable yielding train, test splits.\n",
      " |  \n",
      " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      " |      other cases, :class:`KFold` is used.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |  refit : boolean, default=True\n",
      " |      Refit the best estimator with the entire dataset.\n",
      " |      If \"False\", it is impossible to make predictions using\n",
      " |      this GridSearchCV instance after fitting.\n",
      " |  \n",
      " |  verbose : integer\n",
      " |      Controls the verbosity: the higher, the more messages.\n",
      " |  \n",
      " |  error_score : 'raise' (default) or numeric\n",
      " |      Value to assign to the score if an error occurs in estimator fitting.\n",
      " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      " |      step, which will always raise the error.\n",
      " |  \n",
      " |  return_train_score : boolean, default=True\n",
      " |      If ``'False'``, the ``cv_results_`` attribute will not include training\n",
      " |      scores.\n",
      " |  \n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import svm, datasets\n",
      " |  >>> from sklearn.model_selection import GridSearchCV\n",
      " |  >>> iris = datasets.load_iris()\n",
      " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      " |  >>> svr = svm.SVC()\n",
      " |  >>> clf = GridSearchCV(svr, parameters)\n",
      " |  >>> clf.fit(iris.data, iris.target)\n",
      " |  ...                             # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n",
      " |  GridSearchCV(cv=None, error_score=...,\n",
      " |         estimator=SVC(C=1.0, cache_size=..., class_weight=..., coef0=...,\n",
      " |                       decision_function_shape=None, degree=..., gamma=...,\n",
      " |                       kernel='rbf', max_iter=-1, probability=False,\n",
      " |                       random_state=None, shrinking=True, tol=...,\n",
      " |                       verbose=False),\n",
      " |         fit_params={}, iid=..., n_jobs=1,\n",
      " |         param_grid=..., pre_dispatch=..., refit=..., return_train_score=...,\n",
      " |         scoring=..., verbose=...)\n",
      " |  >>> sorted(clf.cv_results_.keys())\n",
      " |  ...                             # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS\n",
      " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      " |   'mean_train_score', 'param_C', 'param_kernel', 'params',...\n",
      " |   'rank_test_score', 'split0_test_score',...\n",
      " |   'split0_train_score', 'split1_test_score', 'split1_train_score',...\n",
      " |   'split2_test_score', 'split2_train_score',...\n",
      " |   'std_fit_time', 'std_score_time', 'std_test_score', 'std_train_score'...]\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cv_results_ : dict of numpy (masked) ndarrays\n",
      " |      A dict with keys as column headers and values as columns, that can be\n",
      " |      imported into a pandas ``DataFrame``.\n",
      " |  \n",
      " |      For instance the below given table\n",
      " |  \n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_....|\n",
      " |      +============+===========+============+=================+===+=========+\n",
      " |      |  'poly'    |     --    |      2     |        0.8      |...|    2    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'poly'    |     --    |      3     |        0.7      |...|    4    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.1   |     --     |        0.8      |...|    3    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.2   |     --     |        0.9      |...|    1    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |  \n",
      " |      will be represented by a ``cv_results_`` dict of::\n",
      " |  \n",
      " |          {\n",
      " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      " |                                       mask = [False False False False]...)\n",
      " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      " |                                      mask = [ True  True False False]...),\n",
      " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      " |                                       mask = [False False  True  True]...),\n",
      " |          'split0_test_score'  : [0.8, 0.7, 0.8, 0.9],\n",
      " |          'split1_test_score'  : [0.82, 0.5, 0.7, 0.78],\n",
      " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.82],\n",
      " |          'std_test_score'     : [0.02, 0.01, 0.03, 0.03],\n",
      " |          'rank_test_score'    : [2, 4, 3, 1],\n",
      " |          'split0_train_score' : [0.8, 0.9, 0.7],\n",
      " |          'split1_train_score' : [0.82, 0.5, 0.7],\n",
      " |          'mean_train_score'   : [0.81, 0.7, 0.7],\n",
      " |          'std_train_score'    : [0.03, 0.03, 0.04],\n",
      " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      " |          'mean_score_time'    : [0.007, 0.06, 0.04, 0.04],\n",
      " |          'std_score_time'     : [0.001, 0.002, 0.003, 0.005],\n",
      " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      " |          }\n",
      " |  \n",
      " |      NOTE that the key ``'params'`` is used to store a list of parameter\n",
      " |      settings dict for all the parameter candidates.\n",
      " |  \n",
      " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      " |      ``std_score_time`` are all in seconds.\n",
      " |  \n",
      " |  best_estimator_ : estimator\n",
      " |      Estimator that was chosen by the search, i.e. estimator\n",
      " |      which gave highest score (or smallest loss if specified)\n",
      " |      on the left out data. Not available if refit=False.\n",
      " |  \n",
      " |  best_score_ : float\n",
      " |      Score of best_estimator on the left out data.\n",
      " |  \n",
      " |  best_params_ : dict\n",
      " |      Parameter setting that gave the best results on the hold out data.\n",
      " |  \n",
      " |  best_index_ : int\n",
      " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      " |      candidate parameter setting.\n",
      " |  \n",
      " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      " |      the parameter setting for the best model, that gives the highest\n",
      " |      mean score (``search.best_score_``).\n",
      " |  \n",
      " |  scorer_ : function\n",
      " |      Scorer function used on the held out data to choose the best\n",
      " |      parameters for the model.\n",
      " |  \n",
      " |  n_splits_ : int\n",
      " |      The number of cross-validation splits (folds/iterations).\n",
      " |  \n",
      " |  Notes\n",
      " |  ------\n",
      " |  The parameters selected are those that maximize the score of the left out\n",
      " |  data, unless an explicit score is passed in which case it is used instead.\n",
      " |  \n",
      " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      " |  reasons if individual jobs take very little time, but may raise errors if\n",
      " |  the dataset is large and not enough memory is available.  A workaround in\n",
      " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      " |  n_jobs`.\n",
      " |  \n",
      " |  See Also\n",
      " |  ---------\n",
      " |  :class:`ParameterGrid`:\n",
      " |      generates all the combinations of a hyperparameter grid.\n",
      " |  \n",
      " |  :func:`sklearn.model_selection.train_test_split`:\n",
      " |      utility function to split the data into a development set usable\n",
      " |      for fitting a GridSearchCV instance and an evaluation set for\n",
      " |      its final evaluation.\n",
      " |  \n",
      " |  :func:`sklearn.metrics.make_scorer`:\n",
      " |      Make a scorer from a performance metric or loss function.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GridSearchCV\n",
      " |      BaseSearchCV\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, param_grid, scoring=None, fit_params=None, n_jobs=1, iid=True, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score='raise', return_train_score=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None, groups=None)\n",
      " |      Run fit with all sets of parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      groups : array-like, with shape (n_samples,), optional\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSearchCV:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Call decision_function on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``decision_function``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  inverse_transform(self, Xt)\n",
      " |      Call inverse_transform on the estimator with the best found params.\n",
      " |      \n",
      " |      Only available if the underlying estimator implements\n",
      " |      ``inverse_transform`` and ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      Xt : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Call predict on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Call predict_log_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_log_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Call predict_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Returns the score on the given data, if the estimator has been refit.\n",
      " |      \n",
      " |      This uses the score defined by ``scoring`` where provided, and the\n",
      " |      ``best_estimator_.score`` method otherwise.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |          Input data, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Call transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator supports ``transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseSearchCV:\n",
      " |  \n",
      " |  best_params_\n",
      " |  \n",
      " |  best_score_\n",
      " |  \n",
      " |  grid_scores_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "help(GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"alpha\":alpha_space}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To select a scoring parameter in sklearn, see:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "- GridSearchCV and RandomizedSearchCV evaluate each parameter setting independently. Computations can be run in parallel if your OS supports it, by using the keyword n_jobs=-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'alpha': array([ 1.     ,  0.94737,  0.89474,  0.84211,  0.78947,  0.73684,\n",
       "        0.68421,  0.63158,  0.57895,  0.52632,  0.47368,  0.42105,\n",
       "        0.36842,  0.31579,  0.26316,  0.21053,  0.15789,  0.10526,\n",
       "        0.05263,  0.     ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the GridSearchCV object:\n",
    "ridgemodel = Ridge()\n",
    "ridge_cv = GridSearchCV(estimator= ridgemodel,\n",
    "                        param_grid= param_grid,\n",
    "                        scoring='neg_mean_squared_error',\n",
    "                        cv = 5, \n",
    "                        n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to training data to start parameter search:\n",
    "ridge_cv.fit(X_train_transformed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Ridge Regression Parameters: {'alpha': 0.68421052631578949}\n",
      "Best score is -0.40786863934749973\n"
     ]
    }
   ],
   "source": [
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Ridge Regression Parameters: {}\".format(ridge_cv.best_params_)) \n",
    "print(\"Best score is {}\".format(ridge_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the score is **negative mean-squared error**. We found that the optimal alpha is close to 0.68, which was higher than the alpha we used in the model1. Let's make predictions in test set to compare this new tuned model with the earlier model we used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = ridge_cv.predict(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63839912322227732"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_train,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD9CAYAAACcJ53WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niqIoMYYKt6IoSoyhwq0oihJj/B8OcNVP5D7gZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146f8898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(y_pred2,y_train, s = 0.2, c = \"r\", alpha = 0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ed597b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_pred2,y_pred1, s = 0.5, c = \"b\", alpha = 0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, we note that even after hyperparameter tuning, the predictive performance of the Ridge remained a the same level as they are making the same predictions. \n",
    "\n",
    "Next, we try to see if we can include interaction terms into the pipeline to see if we can improve model performance.\n",
    "\n",
    "## Adding feature interaction terms into pipeline\n",
    "\n",
    "This is a custom function that is compatible with SparseMatrices:\n",
    "\n",
    "https://github.com/drivendataorg/box-plots-sklearn/blob/master/src/features/SparseInteractions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class SparseInteractions(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, degree=2, feature_name_separator=\"_\"):\n",
    "        self.degree = degree\n",
    "        self.feature_name_separator = feature_name_separator\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not sparse.isspmatrix_csc(X):\n",
    "            X = sparse.csc_matrix(X)\n",
    "\n",
    "        if hasattr(X, \"columns\"):\n",
    "            self.orig_col_names = X.columns\n",
    "        else:\n",
    "            self.orig_col_names = np.array([str(i) for i in range(X.shape[1])])\n",
    "\n",
    "        spi = self._create_sparse_interactions(X)\n",
    "        return spi\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        return self.feature_names\n",
    "\n",
    "    def _create_sparse_interactions(self, X):\n",
    "        out_mat = []\n",
    "        self.feature_names = self.orig_col_names.tolist()\n",
    "\n",
    "        for sub_degree in range(2, self.degree + 1):\n",
    "            for col_ixs in combinations(range(X.shape[1]), sub_degree):\n",
    "                # add name for new column\n",
    "                name = self.feature_name_separator.join(self.orig_col_names[list(col_ixs)])\n",
    "                self.feature_names.append(name)\n",
    "\n",
    "                # get column multiplications value\n",
    "                out = X[:, col_ixs[0]]\n",
    "                for j in col_ixs[1:]:\n",
    "                    out = out.multiply(X[:, j])\n",
    "\n",
    "                out_mat.append(out)\n",
    "\n",
    "        return sparse.hstack([X] + out_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save this function as SparseInteractions.py into our working directory in order to call it later for easy loading.\n",
    "\n",
    "We will now modify our pipeline that incorporates the step that adds interaction terms. We will also include to load and process the holdout data for final validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#############################################################################\n",
    "# Re-read the training and hold out data\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\", header=None, names= [\"price\"])\n",
    "y_train = y_train.price.values\n",
    "\n",
    "X_holdout = pd.read_csv(\"X_holdout.csv\")\n",
    "y_holdout = pd.read_csv(\"y_holdout.csv\", header=None, names= [\"price\"])\n",
    "y_holdout = y_holdout.price.values\n",
    "\n",
    "#############################################################################\n",
    "# Re-read the pickled feature names\n",
    "import pickle\n",
    "with open(\"Numeric_features.pkl\", 'rb') as f:\n",
    "    Numeric_features = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "with open(\"Text_features.pkl\", 'rb') as f:\n",
    "    Text_features = pickle.load(f)\n",
    "f.close()\n",
    "#############################################################################\n",
    "\n",
    "def column_text_processer(df,text_columns = Text_features):\n",
    "    \"\"\"\"A function that will merge/join all text in a given row to make it ready for tokenization. \n",
    "    - This function should take care of converting missing values to empty strings. \n",
    "    - It should also convert the text to lowercase.\n",
    "    df= pandas dataframe\n",
    "    text_columns = names of the text features in df\n",
    "    \"\"\" \n",
    "    # Select only non-text columns that are in the df\n",
    "    text_data = df[text_columns]\n",
    "    \n",
    "    # Fill the missing values in text_data using empty strings\n",
    "    text_data.fillna(\"\",inplace=True)\n",
    "    \n",
    "    # Join all the strings in a given row to make a vector\n",
    "    text_vector = text_data.apply(lambda x: \" \".join(x), axis = 1)\n",
    "    \n",
    "    # Convert all the text to lowercase and return as pd.Series object to enter the tokenization pipeline\n",
    "    return text_vector.apply(lambda x: x.lower())  \n",
    "\n",
    "#############################################################################\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler, Imputer, FunctionTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "#############################################################################\n",
    "# Utility functions to parse text and numeric features\n",
    "get_numeric_data = FunctionTransformer(func = lambda x: x[Numeric_features], validate=False) #Note x is by default the tensor that contains all features\n",
    "get_text_data = FunctionTransformer(column_text_processer,validate=False) # Note how we avoid putting any arguments into column_text_processer\n",
    "#############################################################################\n",
    "\n",
    "#############################################################################\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'   #Note this regex will match either a whitespace or a punctuation to tokenize the string vector on these preferences  \n",
    "\n",
    "#############################################################################\n",
    "# Define f_regression for feature selection to convert center = False default\n",
    "def f_regression(X,Y):\n",
    "    import sklearn\n",
    "    return sklearn.feature_selection.f_regression(X,Y,center = False) # default is center = True\n",
    "\n",
    "#############################################################################\n",
    "# Prepare the modified pipeline (pl2):\n",
    "\n",
    "pl2 = Pipeline([\n",
    "    \n",
    "    (\"union\",FeatureUnion(        #Note that FeatureUnion() accepts list of tuples, the first half of each tuple is the name of the transformer\n",
    "        \n",
    "        transformer_list = [\n",
    "            \n",
    "            (\"numeric_subpipeline\", Pipeline([        #Note we have subpipeline branches inside the main pipeline\n",
    "                \n",
    "                (\"parser\",get_numeric_data), # Step1: parse the numeric data (note how we avoid () when using FunctionTransformer objects)\n",
    "                (\"imputer\",Imputer()), # Step2: impute missing values\n",
    "            \n",
    "            ])), # Branching point of the FeatureUnion\n",
    "            \n",
    "            (\"text_subpipeline\",Pipeline([\n",
    "            \n",
    "                (\"parser\",get_text_data), # Step1: parse the text data \n",
    "                (\"tokenizer\",HashingVectorizer(token_pattern= TOKENS_ALPHANUMERIC,\n",
    "                                             stop_words = \"english\",# We will remove English stop words before tokenization\n",
    "                                             ngram_range = (1,3),\n",
    "                                             non_negative=True, norm=None, binary=False  \n",
    "                                            )), # Step2: use CountVectorizer for automated tokenization and feature extraction\n",
    "                                            ('dim_red1', SelectKBest(f_regression, 300)) # Step3: use dimension reduction to select 300 best features\n",
    "                \n",
    "            ]))\n",
    "        ]\n",
    "    \n",
    "    )),# Branching point to the main pipeline: at this point all fearures are numeric\n",
    "    \n",
    "    (\"int\", SparseInteractions(degree=2)), # Add polynomial interaction terms \n",
    "    (\"scaler\",MaxAbsScaler()), # Scale the features\n",
    "    ('dim_red2', SelectKBest(f_regression, 400)) # Add another dimension reduction step at the end\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use the new pipeline (pl2) to transform X_train and X_holdout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:279: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= row_norms(X.T)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:279: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= row_norms(X.T)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "# We fit_transform X outside of the pipeline to obtain transformed X for hyperparameter search, \n",
    "# since transformation step takes long time and we want to avoid repeating everytime \n",
    "X_train_transformed = pl2.fit_transform(X_train,y_train)\n",
    "X_holdout_transformed = pl2.fit_transform(X_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889521, 400)\n",
      "(593014, 400)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_transformed.shape)\n",
    "print(X_holdout_transformed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that as we designed, our pipelines provided data sets with 400 features at the end. Next, we fit the new Ridge model using the training set transformed by the modified pipeline (pl2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64640722157857955"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "model2 = Ridge(alpha=0.5)\n",
    "model2.fit(X_train_transformed,y_train)\n",
    "y_pred2 = model2.predict(X_train_transformed) \n",
    "np.sqrt(mean_squared_error(y_train,y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the RMSE in the holdout set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0222330776410204"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = model2.predict(X_holdout_transformed) \n",
    "np.sqrt(mean_squared_error(y_holdout,y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like addition of interaction terms did not increase model performance in our problem. Let's finally try hyperparameter tuning in this scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'alpha': array([ 1.     ,  0.88889,  0.77778,  0.66667,  0.55556,  0.44444,\n",
       "        0.33333,  0.22222,  0.11111,  0.     ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "alphas = np.linspace(1,0,10)\n",
    "param_grid = {\"alpha\":alphas}\n",
    "# Instantiate the GridSearchCV object:\n",
    "ridgemodel = Ridge()\n",
    "ridge_cv = GridSearchCV(estimator= ridgemodel,\n",
    "                        param_grid= param_grid,\n",
    "                        scoring='neg_mean_squared_error',\n",
    "                        cv = 5, \n",
    "                        n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to training data to start parameter search:\n",
    "ridge_cv.fit(X_train_transformed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.11111111111111116}\n",
      "-0.418277136487\n"
     ]
    }
   ],
   "source": [
    "print(ridge_cv.best_params_)\n",
    "print(ridge_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64638127028157599"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred2 = ridge_cv.predict(X_train_transformed) \n",
    "np.sqrt(mean_squared_error(y_train,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0569031945809519"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = ridge_cv.predict(X_holdout_transformed) \n",
    "np.sqrt(mean_squared_error(y_holdout,y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning has marginal impact on the model performance. As a final step, let's modify the pipeline 2, by removing the final feature selection step and see if that changes model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the modified pipeline (pl3):\n",
    "pl3 = Pipeline([\n",
    "    \n",
    "    (\"union\",FeatureUnion(        #Note that FeatureUnion() accepts list of tuples, the first half of each tuple is the name of the transformer\n",
    "        \n",
    "        transformer_list = [\n",
    "            \n",
    "            (\"numeric_subpipeline\", Pipeline([        #Note we have subpipeline branches inside the main pipeline\n",
    "                \n",
    "                (\"parser\",get_numeric_data), # Step1: parse the numeric data (note how we avoid () when using FunctionTransformer objects)\n",
    "                (\"imputer\",Imputer()), # Step2: impute missing values\n",
    "            \n",
    "            ])), # Branching point of the FeatureUnion\n",
    "            \n",
    "            (\"text_subpipeline\",Pipeline([\n",
    "            \n",
    "                (\"parser\",get_text_data), # Step1: parse the text data \n",
    "                (\"tokenizer\",HashingVectorizer(token_pattern= TOKENS_ALPHANUMERIC,\n",
    "                                             stop_words = \"english\",# We will remove English stop words before tokenization\n",
    "                                             ngram_range = (1,3),\n",
    "                                             non_negative=True, norm=None, binary=False  \n",
    "                                            )), # Step2: use CountVectorizer for automated tokenization and feature extraction\n",
    "                                            ('dim_red1', SelectKBest(f_regression, 300)) # Step3: use dimension reduction to select 300 best features\n",
    "                \n",
    "            ]))\n",
    "        ]\n",
    "    \n",
    "    )),# Branching point to the main pipeline: at this point all fearures are numeric\n",
    "    \n",
    "    (\"int\", SparseInteractions(degree=2)), # Add polynomial interaction terms \n",
    "    (\"scaler\",MaxAbsScaler()), # Scale the features\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:279: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= row_norms(X.T)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:279: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= row_norms(X.T)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "X_train_transformed = pl3.fit_transform(X_train, y_train)\n",
    "X_holdout_transformed = pl3.fit_transform(X_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889521, 45753)\n",
      "(593014, 45753)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_transformed.shape)\n",
    "print(X_holdout_transformed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that by creating interaction terms, we increased the dimension of data enourmously. We will now try Ridge regularization to see if we can improve our previous model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-6469ef47732f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_transformed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mypred3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred3' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "model3 = Ridge(alpha = 0.5)\n",
    "model3.fit(X_train_transformed,y_train)\n",
    "ypred3 = model3.predict(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57418678100605181"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_train,ypred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD9CAYAAACcJ53WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIBAIogxiuAUCgSDKIIZbIBAIogz/D7ineDI35Va7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1324e8400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(ypred3,y_train, s = 0.3, c = 'r', alpha = 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95170781413293182"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the performance in the holdout set\n",
    "ypred3_holdout = model3.predict(X_holdout_transformed)\n",
    "np.sqrt(mean_squared_error(y_holdout,ypred3_holdout))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model performance is remarkably better. Therefore, we learned that once added the interaction terms, we can leave the features as they are, as long as we are tempted to perform regularization afterwards. \n",
    "\n",
    "However, one point we noticed here is that: if we perform fit_transform of the data set outside of the pipeline, this can potentially bias to X_holdout because new features are extracted. Instead, we should fit(train) the entire pipeline using the X_train and y_train, then only use predict with X_holdout. \n",
    "\n",
    "Let's incorporate the model step into our best performing pipeline, pl3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SparseInteractions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b74f18b18e88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m     )),# Branching point to the main pipeline: at this point all fearures are numeric\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"int\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparseInteractions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Add polynomial interaction terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"scaler\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMaxAbsScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Scale the features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"reg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Add the RidgeRegression step using alpha = 0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SparseInteractions' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#############################################################################\n",
    "# Re-read the training and hold out data\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\", header=None, names= [\"price\"])\n",
    "y_train = y_train.price.values\n",
    "\n",
    "X_holdout = pd.read_csv(\"X_holdout.csv\")\n",
    "y_holdout = pd.read_csv(\"y_holdout.csv\", header=None, names= [\"price\"])\n",
    "y_holdout = y_holdout.price.values\n",
    "\n",
    "#############################################################################\n",
    "# Re-read the pickled feature names\n",
    "import pickle\n",
    "with open(\"Numeric_features.pkl\", 'rb') as f:\n",
    "    Numeric_features = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "with open(\"Text_features.pkl\", 'rb') as f:\n",
    "    Text_features = pickle.load(f)\n",
    "f.close()\n",
    "#############################################################################\n",
    "\n",
    "def column_text_processer(df,text_columns = Text_features):\n",
    "    \"\"\"\"A function that will merge/join all text in a given row to make it ready for tokenization. \n",
    "    - This function should take care of converting missing values to empty strings. \n",
    "    - It should also convert the text to lowercase.\n",
    "    df= pandas dataframe\n",
    "    text_columns = names of the text features in df\n",
    "    \"\"\" \n",
    "    # Select only non-text columns that are in the df\n",
    "    text_data = df[text_columns]\n",
    "    \n",
    "    # Fill the missing values in text_data using empty strings\n",
    "    text_data.fillna(\"\",inplace=True)\n",
    "    \n",
    "    # Join all the strings in a given row to make a vector\n",
    "    text_vector = text_data.apply(lambda x: \" \".join(x), axis = 1)\n",
    "    \n",
    "    # Convert all the text to lowercase and return as pd.Series object to enter the tokenization pipeline\n",
    "    return text_vector.apply(lambda x: x.lower())  \n",
    "\n",
    "#############################################################################\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler, Imputer, FunctionTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#############################################################################\n",
    "# Utility functions to parse text and numeric features\n",
    "get_numeric_data = FunctionTransformer(func = lambda x: x[Numeric_features], validate=False) #Note x is by default the tensor that contains all features\n",
    "get_text_data = FunctionTransformer(column_text_processer,validate=False) # Note how we avoid putting any arguments into column_text_processer\n",
    "#############################################################################\n",
    "\n",
    "#############################################################################\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'   #Note this regex will match either a whitespace or a punctuation to tokenize the string vector on these preferences  \n",
    "\n",
    "#############################################################################\n",
    "# Define f_regression for feature selection to convert center = False default\n",
    "def f_regression(X,Y):\n",
    "    import sklearn\n",
    "    return sklearn.feature_selection.f_regression(X,Y,center = False) # default is center = True\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "pl3 = Pipeline([\n",
    "    \n",
    "    (\"union\",FeatureUnion(        #Note that FeatureUnion() accepts list of tuples, the first half of each tuple is the name of the transformer\n",
    "        \n",
    "        transformer_list = [\n",
    "            \n",
    "            (\"numeric_subpipeline\", Pipeline([        #Note we have subpipeline branches inside the main pipeline\n",
    "                \n",
    "                (\"parser\",get_numeric_data), # Step1: parse the numeric data (note how we avoid () when using FunctionTransformer objects)\n",
    "                (\"imputer\",Imputer()), # Step2: impute missing values\n",
    "            \n",
    "            ])), # Branching point of the FeatureUnion\n",
    "            \n",
    "            (\"text_subpipeline\",Pipeline([\n",
    "            \n",
    "                (\"parser\",get_text_data), # Step1: parse the text data \n",
    "                (\"tokenizer\",HashingVectorizer(token_pattern= TOKENS_ALPHANUMERIC,\n",
    "                                             stop_words = \"english\",# We will remove English stop words before tokenization\n",
    "                                             ngram_range = (1,3),\n",
    "                                             non_negative=True, norm=None, binary=False  \n",
    "                                            )), # Step2: use CountVectorizer for automated tokenization and feature extraction\n",
    "                                            ('dim_red1', SelectKBest(f_regression, 300)) # Step3: use dimension reduction to select 300 best features\n",
    "                \n",
    "            ]))\n",
    "        ]\n",
    "    \n",
    "    )),# Branching point to the main pipeline: at this point all fearures are numeric\n",
    "    \n",
    "    (\"int\", SparseInteractions(degree=2)), # Add polynomial interaction terms \n",
    "    (\"scaler\",MaxAbsScaler()), # Scale the features\n",
    "    (\"reg\",Ridge(alpha = 0.5)) # Add the RidgeRegression step using alpha = 0.5\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:279: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= row_norms(X.T)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('union', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('numeric_subpipeline', Pipeline(steps=[('parser', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function <lambda> at 0x152b9e840>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args=None, pass_y=False, validate=False)),...it_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train our pipeline using training set\n",
    "pl3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.57418695057696534"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions first using the training set\n",
    "y_pred3 = pl3.predict(X_train)\n",
    "np.sqrt(mean_squared_error(y_train,y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected, we were able to reproduce the rmse using the pipeline object's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.60209449047700869"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions using the holdout set\n",
    "y_pred3 = pl3.predict(X_holdout)\n",
    "np.sqrt(mean_squared_error(y_holdout,y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very nice! Now we learned that it is essential to only include the modeling step inside the pipeline. We notice that the performance of our pipeline in the holdout set is actually quite good, better than any model we used before. We note that this is a data set the pipeline has not seen before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD9CAYAAACcJ53WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nN3ebAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1317489b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_pred3,y_holdout, s = 0.3, c = \"r\", alpha = 0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try to perform Gridsearch over the pipeline3 we established. This way we will try to learn:\n",
    "\n",
    "1. How to perform Gridsearch using an entire pipeline: tuning multiple hyperparameters\n",
    "2. How to improve computational efficiency of this process (read Pipeline documentation, e.g: cache)\n",
    "3. To understand if we can further improve the performance of the existing pipeline!\n",
    "\n",
    "## GridSearch using entire Ridge pipeline\n",
    "\n",
    "Let's get started by loading our data sets, utility functions and the latest pipeline using which we would like to perform hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from SparseInteractions import * #Load SparseInteractions as a module since it was saved into working directory as SparseInteractions.py\n",
    "\n",
    "#############################################################################\n",
    "# Re-read the training and hold out data\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\", header=None, names= [\"price\"])\n",
    "y_train = y_train.price.values\n",
    "\n",
    "X_holdout = pd.read_csv(\"X_holdout.csv\")\n",
    "y_holdout = pd.read_csv(\"y_holdout.csv\", header=None, names= [\"price\"])\n",
    "y_holdout = y_holdout.price.values\n",
    "\n",
    "#############################################################################\n",
    "# Re-read the pickled feature names\n",
    "import pickle\n",
    "with open(\"Numeric_features.pkl\", 'rb') as f:\n",
    "    Numeric_features = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "with open(\"Text_features.pkl\", 'rb') as f:\n",
    "    Text_features = pickle.load(f)\n",
    "f.close()\n",
    "#############################################################################\n",
    "\n",
    "def column_text_processer(df,text_columns = Text_features):\n",
    "    \"\"\"\"A function that will merge/join all text in a given row to make it ready for tokenization. \n",
    "    - This function should take care of converting missing values to empty strings. \n",
    "    - It should also convert the text to lowercase.\n",
    "    df= pandas dataframe\n",
    "    text_columns = names of the text features in df\n",
    "    \"\"\" \n",
    "    # Select only non-text columns that are in the df\n",
    "    text_data = df[text_columns]\n",
    "    \n",
    "    # Fill the missing values in text_data using empty strings\n",
    "    text_data.fillna(\"\",inplace=True)\n",
    "    \n",
    "    # Join all the strings in a given row to make a vector\n",
    "    text_vector = text_data.apply(lambda x: \" \".join(x), axis = 1)\n",
    "    \n",
    "    # Convert all the text to lowercase and return as pd.Series object to enter the tokenization pipeline\n",
    "    return text_vector.apply(lambda x: x.lower())  \n",
    "\n",
    "#############################################################################\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler, Imputer, FunctionTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#############################################################################\n",
    "# Utility functions to parse text and numeric features\n",
    "get_numeric_data = FunctionTransformer(func = lambda x: x[Numeric_features], validate=False) #Note x is by default the tensor that contains all features\n",
    "get_text_data = FunctionTransformer(column_text_processer,validate=False) # Note how we avoid putting any arguments into column_text_processer\n",
    "#############################################################################\n",
    "\n",
    "#############################################################################\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'   #Note this regex will match either a whitespace or a punctuation to tokenize the string vector on these preferences  \n",
    "\n",
    "#############################################################################\n",
    "# Define f_regression for feature selection to convert center = False default\n",
    "def f_regression(X,Y):\n",
    "    import sklearn\n",
    "    return sklearn.feature_selection.f_regression(X,Y,center = False) # default is center = True\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "pl3 = Pipeline([\n",
    "    \n",
    "    (\"union\",FeatureUnion(        #Note that FeatureUnion() accepts list of tuples, the first half of each tuple is the name of the transformer\n",
    "        \n",
    "        transformer_list = [\n",
    "            \n",
    "            (\"numeric_subpipeline\", Pipeline([        #Note we have subpipeline branches inside the main pipeline\n",
    "                \n",
    "                (\"parser\",get_numeric_data), # Step1: parse the numeric data (note how we avoid () when using FunctionTransformer objects)\n",
    "                (\"imputer\",Imputer()), # Step2: impute missing values\n",
    "            \n",
    "            ])), # Branching point of the FeatureUnion\n",
    "            \n",
    "            (\"text_subpipeline\",Pipeline([\n",
    "            \n",
    "                (\"parser\",get_text_data), # Step1: parse the text data \n",
    "                (\"tokenizer\",HashingVectorizer(token_pattern= TOKENS_ALPHANUMERIC,\n",
    "                                             stop_words = \"english\",# We will remove English stop words before tokenization\n",
    "                                             ngram_range = (1,3),\n",
    "                                             non_negative=True, norm=None, binary=False  \n",
    "                                            )), # Step2: use CountVectorizer for automated tokenization and feature extraction\n",
    "                                            ('dim_red1', SelectKBest(f_regression, 300)) # Step3: use dimension reduction to select 300 best features\n",
    "                \n",
    "            ]))\n",
    "        ]\n",
    "    \n",
    "    )),# Branching point to the main pipeline: at this point all fearures are numeric\n",
    "    \n",
    "    (\"int\", SparseInteractions(degree=2)), # Add polynomial interaction terms \n",
    "    (\"scaler\",MaxAbsScaler()), # Scale the features\n",
    "    (\"reg\",Ridge(alpha = 0.5)) # Add the RidgeRegression step using alpha = 0.5\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look into the potential parameters we can tune in our pipeline, using .get_params() method of the pipeline object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'int': SparseInteractions(degree=2, feature_name_separator='_'),\n",
       " 'int__degree': 2,\n",
       " 'int__feature_name_separator': '_',\n",
       " 'memory': None,\n",
       " 'reg': Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "    normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       " 'reg__alpha': 0.5,\n",
       " 'reg__copy_X': True,\n",
       " 'reg__fit_intercept': True,\n",
       " 'reg__max_iter': None,\n",
       " 'reg__normalize': False,\n",
       " 'reg__random_state': None,\n",
       " 'reg__solver': 'auto',\n",
       " 'reg__tol': 0.001,\n",
       " 'scaler': MaxAbsScaler(copy=True),\n",
       " 'scaler__copy': True,\n",
       " 'steps': [('union', FeatureUnion(n_jobs=1,\n",
       "          transformer_list=[('numeric_subpipeline', Pipeline(memory=None,\n",
       "        steps=[('parser', FunctionTransformer(accept_sparse=False,\n",
       "             func=<function <lambda> at 0x111756f28>, inv_kw_args=None,\n",
       "             inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "             validate=False)), ('imputer',...izer=None)), ('dim_red1', SelectKBest(k=300, score_func=<function f_regression at 0x1036cd6a8>))]))],\n",
       "          transformer_weights=None)),\n",
       "  ('int', SparseInteractions(degree=2, feature_name_separator='_')),\n",
       "  ('scaler', MaxAbsScaler(copy=True)),\n",
       "  ('reg', Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "      normalize=False, random_state=None, solver='auto', tol=0.001))],\n",
       " 'union': FeatureUnion(n_jobs=1,\n",
       "        transformer_list=[('numeric_subpipeline', Pipeline(memory=None,\n",
       "      steps=[('parser', FunctionTransformer(accept_sparse=False,\n",
       "           func=<function <lambda> at 0x111756f28>, inv_kw_args=None,\n",
       "           inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "           validate=False)), ('imputer',...izer=None)), ('dim_red1', SelectKBest(k=300, score_func=<function f_regression at 0x1036cd6a8>))]))],\n",
       "        transformer_weights=None),\n",
       " 'union__n_jobs': 1,\n",
       " 'union__numeric_subpipeline': Pipeline(memory=None,\n",
       "      steps=[('parser', FunctionTransformer(accept_sparse=False,\n",
       "           func=<function <lambda> at 0x111756f28>, inv_kw_args=None,\n",
       "           inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "           validate=False)), ('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0))]),\n",
       " 'union__numeric_subpipeline__imputer': Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0),\n",
       " 'union__numeric_subpipeline__imputer__axis': 0,\n",
       " 'union__numeric_subpipeline__imputer__copy': True,\n",
       " 'union__numeric_subpipeline__imputer__missing_values': 'NaN',\n",
       " 'union__numeric_subpipeline__imputer__strategy': 'mean',\n",
       " 'union__numeric_subpipeline__imputer__verbose': 0,\n",
       " 'union__numeric_subpipeline__memory': None,\n",
       " 'union__numeric_subpipeline__parser': FunctionTransformer(accept_sparse=False,\n",
       "           func=<function <lambda> at 0x111756f28>, inv_kw_args=None,\n",
       "           inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "           validate=False),\n",
       " 'union__numeric_subpipeline__parser__accept_sparse': False,\n",
       " 'union__numeric_subpipeline__parser__func': <function __main__.<lambda>>,\n",
       " 'union__numeric_subpipeline__parser__inv_kw_args': None,\n",
       " 'union__numeric_subpipeline__parser__inverse_func': None,\n",
       " 'union__numeric_subpipeline__parser__kw_args': None,\n",
       " 'union__numeric_subpipeline__parser__pass_y': 'deprecated',\n",
       " 'union__numeric_subpipeline__parser__validate': False,\n",
       " 'union__numeric_subpipeline__steps': [('parser',\n",
       "   FunctionTransformer(accept_sparse=False,\n",
       "             func=<function <lambda> at 0x111756f28>, inv_kw_args=None,\n",
       "             inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "             validate=False)),\n",
       "  ('imputer',\n",
       "   Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0))],\n",
       " 'union__text_subpipeline': Pipeline(memory=None,\n",
       "      steps=[('parser', FunctionTransformer(accept_sparse=False,\n",
       "           func=<function column_text_processer at 0x12b8d3268>,\n",
       "           inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "           pass_y='deprecated', validate=False)), ('tokenizer', HashingVectorizer(alternate_sign=True, analyzer='word...kenizer=None)), ('dim_red1', SelectKBest(k=300, score_func=<function f_regression at 0x1036cd6a8>))]),\n",
       " 'union__text_subpipeline__dim_red1': SelectKBest(k=300, score_func=<function f_regression at 0x1036cd6a8>),\n",
       " 'union__text_subpipeline__dim_red1__k': 300,\n",
       " 'union__text_subpipeline__dim_red1__score_func': <function __main__.f_regression>,\n",
       " 'union__text_subpipeline__memory': None,\n",
       " 'union__text_subpipeline__parser': FunctionTransformer(accept_sparse=False,\n",
       "           func=<function column_text_processer at 0x12b8d3268>,\n",
       "           inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "           pass_y='deprecated', validate=False),\n",
       " 'union__text_subpipeline__parser__accept_sparse': False,\n",
       " 'union__text_subpipeline__parser__func': <function __main__.column_text_processer>,\n",
       " 'union__text_subpipeline__parser__inv_kw_args': None,\n",
       " 'union__text_subpipeline__parser__inverse_func': None,\n",
       " 'union__text_subpipeline__parser__kw_args': None,\n",
       " 'union__text_subpipeline__parser__pass_y': 'deprecated',\n",
       " 'union__text_subpipeline__parser__validate': False,\n",
       " 'union__text_subpipeline__steps': [('parser',\n",
       "   FunctionTransformer(accept_sparse=False,\n",
       "             func=<function column_text_processer at 0x12b8d3268>,\n",
       "             inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "             pass_y='deprecated', validate=False)),\n",
       "  ('tokenizer',\n",
       "   HashingVectorizer(alternate_sign=True, analyzer='word', binary=False,\n",
       "            decode_error='strict', dtype=<class 'numpy.float64'>,\n",
       "            encoding='utf-8', input='content', lowercase=True,\n",
       "            n_features=1048576, ngram_range=(1, 3), non_negative=True,\n",
       "            norm=None, preprocessor=None, stop_words='english',\n",
       "            strip_accents=None, token_pattern='[A-Za-z0-9]+(?=\\\\s+)',\n",
       "            tokenizer=None)),\n",
       "  ('dim_red1',\n",
       "   SelectKBest(k=300, score_func=<function f_regression at 0x1036cd6a8>))],\n",
       " 'union__text_subpipeline__tokenizer': HashingVectorizer(alternate_sign=True, analyzer='word', binary=False,\n",
       "          decode_error='strict', dtype=<class 'numpy.float64'>,\n",
       "          encoding='utf-8', input='content', lowercase=True,\n",
       "          n_features=1048576, ngram_range=(1, 3), non_negative=True,\n",
       "          norm=None, preprocessor=None, stop_words='english',\n",
       "          strip_accents=None, token_pattern='[A-Za-z0-9]+(?=\\\\s+)',\n",
       "          tokenizer=None),\n",
       " 'union__text_subpipeline__tokenizer__alternate_sign': True,\n",
       " 'union__text_subpipeline__tokenizer__analyzer': 'word',\n",
       " 'union__text_subpipeline__tokenizer__binary': False,\n",
       " 'union__text_subpipeline__tokenizer__decode_error': 'strict',\n",
       " 'union__text_subpipeline__tokenizer__dtype': numpy.float64,\n",
       " 'union__text_subpipeline__tokenizer__encoding': 'utf-8',\n",
       " 'union__text_subpipeline__tokenizer__input': 'content',\n",
       " 'union__text_subpipeline__tokenizer__lowercase': True,\n",
       " 'union__text_subpipeline__tokenizer__n_features': 1048576,\n",
       " 'union__text_subpipeline__tokenizer__ngram_range': (1, 3),\n",
       " 'union__text_subpipeline__tokenizer__non_negative': True,\n",
       " 'union__text_subpipeline__tokenizer__norm': None,\n",
       " 'union__text_subpipeline__tokenizer__preprocessor': None,\n",
       " 'union__text_subpipeline__tokenizer__stop_words': 'english',\n",
       " 'union__text_subpipeline__tokenizer__strip_accents': None,\n",
       " 'union__text_subpipeline__tokenizer__token_pattern': '[A-Za-z0-9]+(?=\\\\s+)',\n",
       " 'union__text_subpipeline__tokenizer__tokenizer': None,\n",
       " 'union__transformer_list': [('numeric_subpipeline', Pipeline(memory=None,\n",
       "        steps=[('parser', FunctionTransformer(accept_sparse=False,\n",
       "             func=<function <lambda> at 0x111756f28>, inv_kw_args=None,\n",
       "             inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "             validate=False)), ('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0))])),\n",
       "  ('text_subpipeline', Pipeline(memory=None,\n",
       "        steps=[('parser', FunctionTransformer(accept_sparse=False,\n",
       "             func=<function column_text_processer at 0x12b8d3268>,\n",
       "             inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "             pass_y='deprecated', validate=False)), ('tokenizer', HashingVectorizer(alternate_sign=True, analyzer='word...kenizer=None)), ('dim_red1', SelectKBest(k=300, score_func=<function f_regression at 0x1036cd6a8>))]))],\n",
       " 'union__transformer_weights': None}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl3.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We notice that the following parameters would be intuitive to tune through GridSearchCV:\n",
    "\n",
    "'reg__alpha': 0.5\n",
    "'union__text_subpipeline__dim_red1__k': 300,\n",
    "'union__text_subpipeline__tokenizer__ngram_range': (1, 3)\n",
    "'int__degree': 2\n",
    "\n",
    "# Let's set up a hyperparameter space to use GridSearchCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'reg__alpha': np.linspace(1,0,10),\n",
    "    'union__text_subpipeline__dim_red1__k': [200,300,400],\n",
    "    'union__text_subpipeline__tokenizer__ngram_range': [(1,3),(1,4)], # We will tokenize for up to 4-grams \n",
    "    'int__degree': [2,3] # We will add up to the third polymonial degree interactions \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will set up our GridSearchCV estimator using the hyperparameter space we just defined. \n",
    "\n",
    "As a slight modification, here we will use the memory and cache functions of the sklearn in order to save some time in computations.\n",
    "\n",
    "### Catching the transformers within a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "(\"Can't pickle <function <lambda> at 0x111756f28>: it's not found as __main__.<lambda>\", 'PicklingError while hashing {\\'transformer\\': FeatureUnion(n_jobs=1,\\n       transformer_list=[(\\'numeric_subpipeline\\', Pipeline(memory=None,\\n     steps=[(\\'parser\\', FunctionTransformer(accept_sparse=False,\\n          func=<function <lambda> at 0x111756f28>, inv_kw_args=None,\\n          inverse_func=None, kw_args=None, pass_y=\\'deprecated\\',\\n          validate=False)), (\\'imputer\\',...izer=None)), (\\'dim_red1\\', SelectKBest(k=200, score_func=<function f_regression at 0x1036cd6a8>))]))],\\n       transformer_weights=None), \\'weight\\': None, \\'X\\':                                              name  item_condition_id  \\\\\\n296507         Fluffy pom pom knit infinity scarf                  4   \\n296508            Flannel Abercrombie button down                  2   \\n296509                            RAE DUNN BUNDLE                  1   \\n296510                          Baby girl blanket                  1   \\n296511                 New lularoe os cool pandas                  1   \\n296512                     Nike Air Presto (wmns)                  2   \\n296513                      7y nike nike free 5.0                  3   \\n296514    Bundle 2pairs of jeans and I pair chino                  1   \\n296515        LuLaRoe OS raccoons nwt unicorn HTF                  1   \\n296516                              VS Pink socks                  3   \\n296517                               Cactus Decal                  1   \\n296518                              Beats Mix Pro                  3   \\n296519                   NWT Lularoe Nicole small                  1   \\n296520                            VS PINK M Lexie                  1   \\n296521               Kendra Scoot Bexley Earrings                  1   \\n296522                            Women\\'s Sweater                  1   \\n296523                      Cartier Love Bracelet                  1   \\n296524                         Black toddler vans                  3   \\n296525       White House Black Market Skirt White                  3   \\n296526               2 shirts + makeup bag bundle                  3   \\n296527   SALE.!! 2 LARGE PINK BOYSHORTS FREE SHIP                  1   \\n296528                      Victoria\\'s Secret hat                  1   \\n296529        Bandolino Madia Dress Sandals Black                  2   \\n296530               Pittsburgh Steelers Headband                  1   \\n296531                         Under Amour Hoodie                  3   \\n296532     Littlest pet shop clothing accessories                  3   \\n296533                           Funko pop Elvira                  1   \\n296534     Levies women\\'s 10 Long classic bootcut                  3   \\n296535      High wasted swimsuit READ DESCRIPTION                  1   \\n296536                    Harry Potter adult robe                  3   \\n...                                           ...                ...   \\n889491        Gain Laundry & Colgate & Angel Soft                  1   \\n889492     Bright pink iridescent faux druzy ring                  1   \\n889493                          Iphone 5 gun case                  4   \\n889494         NWT! Vans 1.5 (Mesh) Eclipse/White                  1   \\n889495   ✨Anastacia Beverly Hills, Medium to Tan✨                  3   \\n889496    Livin free eagle texas graphic mesh tee                  2   \\n889497                    Bundle of 2 Summer Tops                  1   \\n889498           Festival Crochet Halter Crop Top                  3   \\n889499  SUPERSALE APPLE iPhone 6 Charger [rm]each                  1   \\n889500     NWT Urban Republic boys hoodie coat 4T                  1   \\n889501                Vintage by Jeffrey Campbell                  3   \\n889502                              Nude Bodysuit                  2   \\n889503                          Men\\'s Nixon watch                  3   \\n889504                                    2 Black                  2   \\n889505   Nike air shoes size 6C toddler baby girl                  2   \\n889506                          Mary Kay Compacts                  1   \\n889507                         VS bronzing mousse                  1   \\n889508                      Retro 5s sons of mars                  3   \\n889509    Kat Von D Holographic Alchemist Palette                  2   \\n889510                  Earrings and necklace set                  1   \\n889511            4 LIFE IMPROVEMENT BOOKS BUNDLE                  3   \\n889512               3 pc mini Chanel makeup pack                  1   \\n889513                              Learn crochet                  3   \\n889514          Reserved for BUKA - WDW Purple SE                  4   \\n889515          Fitbit Charge 2 Band - Light Pink                  1   \\n889516                          Cute summer dress                  1   \\n889517                Garnier Fructis Conditioner                  1   \\n889518                                     Bundle                  3   \\n889519            TMNT Raphael Costume (8) f/ship                  1   \\n889520                  Medium one piece swimsuit                  1   \\n\\n                                            category_name  \\\\\\n296507          Women/Women\\'s Accessories/Scarves & Wraps   \\n296508             Women/Tops & Blouses/Button Down Shirt   \\n296509     Home/Kitchen & Dining/Coffee & Tea Accessories   \\n296510                               Kids/Nursery/Bedding   \\n296511     Women/Athletic Apparel/Pants, Tights, Leggings   \\n296512                               Women/Shoes/Athletic   \\n296513                               Women/Shoes/Athletic   \\n296514                             Men/Jeans/Slim, Skinny   \\n296515                               Women/Jeans/Leggings   \\n296516                       Women/Athletic Apparel/Socks   \\n296517                       Handmade/Paper Goods/Sticker   \\n296518    Electronics/TV, Audio & Surveillance/Headphones   \\n296519                          Women/Dresses/Knee-Length   \\n296520                            Women/Underwear/Panties   \\n296521                             Women/Jewelry/Earrings   \\n296522                            Women/Sweaters/Cardigan   \\n296523                            Women/Jewelry/Bracelets   \\n296524                              Kids/Boys 2T-5T/Shoes   \\n296525                      Women/Skirts/Straight, Pencil   \\n296526                    Kids/Boys 2T-5T/Tops & T-Shirts   \\n296527                            Women/Underwear/Panties   \\n296528                     Women/Women\\'s Accessories/Hats   \\n296529                                Women/Shoes/Sandals   \\n296530                     Sports & Outdoors/Fan Shop/NFL   \\n296531                              Women/Sweaters/Hooded   \\n296532                      Kids/Toys/Dolls & Accessories   \\n296533           Vintage & Collectibles/Toy/Action Figure   \\n296534                               Women/Jeans/Boot Cut   \\n296535                           Women/Swimwear/Two-Piece   \\n296536                                  Other/Other/Other   \\n...                                                   ...   \\n889491          Home/Cleaning Supplies/Household Cleaners   \\n889492                                Women/Jewelry/Rings   \\n889493  Electronics/Cell Phones & Accessories/Cases, C...   \\n889494                       Women/Shoes/Fashion Sneakers   \\n889495                      Beauty/Makeup/Makeup Palettes   \\n889496                    Women/Tops & Blouses/Tank, Cami   \\n889497                    Women/Tops & Blouses/Tank, Cami   \\n889498                        Women/Tops & Blouses/Halter   \\n889499  Electronics/Cell Phones & Accessories/Cables &...   \\n889500                     Kids/Boys (4+)/Coats & Jackets   \\n889501                          Women/Shoes/Mules & Clogs   \\n889502                           Women/Swimwear/One-Piece   \\n889503                      Men/Men\\'s Accessories/Watches   \\n889504                        Women/Tops & Blouses/Blouse   \\n889505                             Kids/Girls 2T-5T/Shoes   \\n889506                                 Beauty/Makeup/Eyes   \\n889507                             Beauty/Fragrance/Women   \\n889508                                 Men/Shoes/Athletic   \\n889509                      Beauty/Makeup/Makeup Palettes   \\n889510                            Women/Jewelry/Necklaces   \\n889511                  Vintage & Collectibles/Book/Other   \\n889512  Beauty/Tools & Accessories/Makeup Brushes & Tools   \\n889513                          Handmade/Patterns/Crochet   \\n889514                        Kids/Girls 0-24 Mos/Dresses   \\n889515      Sports & Outdoors/Exercise/Fitness technology   \\n889516                     Women/Dresses/Above Knee, Mini   \\n889517        Beauty/Hair Care/Shampoo & Conditioner Sets   \\n889518                             Kids/Girls 2T-5T/Shoes   \\n889519                  Kids/Toys/Dress Up & Pretend Play   \\n889520                           Women/Swimwear/One-Piece   \\n\\n                      brand_name  shipping  \\\\\\n296507                       NaN         0   \\n296508       Abercrombie & Fitch         0   \\n296509                  Rae Dunn         0   \\n296510                       NaN         1   \\n296511                       NaN         1   \\n296512                      Nike         1   \\n296513                      Nike         0   \\n296514                       NaN         1   \\n296515                       NaN         0   \\n296516                      PINK         1   \\n296517                       NaN         1   \\n296518          Beats by Dr. Dre         0   \\n296519                   LuLaRoe         0   \\n296520         Victoria\\'s Secret         1   \\n296521              Kendra Scott         1   \\n296522            New Directions         0   \\n296523                   Cartier         0   \\n296524                       NaN         0   \\n296525  White House Black Market         0   \\n296526                       NaN         0   \\n296527                      PINK         1   \\n296528         Victoria\\'s Secret         0   \\n296529                 Bandolino         0   \\n296530                       NaN         1   \\n296531              Under Armour         1   \\n296532                    Hasbro         0   \\n296533                     Funko         0   \\n296534                   Levi\\'s®         0   \\n296535                       NaN         0   \\n296536                       NaN         1   \\n...                          ...       ...   \\n889491                       NaN         0   \\n889492                       NaN         1   \\n889493                       NaN         1   \\n889494                      VANS         1   \\n889495                   Sephora         1   \\n889496                FOREVER 21         0   \\n889497                       NaN         1   \\n889498                       NaN         0   \\n889499                     Apple         1   \\n889500                   Arizona         0   \\n889501          Jeffrey Campbell         0   \\n889502                FOREVER 21         0   \\n889503                     Nixon         0   \\n889504                   Express         0   \\n889505                      Nike         0   \\n889506                  Mary Kay         0   \\n889507         Victoria\\'s Secret         1   \\n889508                    Jordan         0   \\n889509                 Kat Von D         0   \\n889510                       NaN         1   \\n889511                       NaN         0   \\n889512                    Chanel         1   \\n889513                       NaN         0   \\n889514                       NaN         1   \\n889515                       NaN         1   \\n889516                     Ariat         0   \\n889517                   Garnier         0   \\n889518                  Gymboree         0   \\n889519                       NaN         1   \\n889520                       NaN         1   \\n\\n                                         item_description  \\n296507  Cute cream colored infinity scarf with knit po...  \\n296508  Flannel shirt by Abercrombie. Size large. Supe...  \\n296509  PRICE IS FOR ALL THREE // CANT BE BOUGHT SEPAR...  \\n296510  I can take off the hanger if you would like ju...  \\n296511  New lularoe one size cool pandas with glasses ...  \\n296512  Size 7, brand new never worn! Ended up finding...  \\n296513  Women size 9 Good conditions Fast shipping No ...  \\n296514  Reserved for Mess_cx I pair of Bullhead light ...  \\n296515  LuLaRoe OS size raccoon leggings. Red and blue...  \\n296516  EUC These have been washed, I attempted to wea...  \\n296517      4 \" Decal Yeti decal Monogram decal Car decal  \\n296518                     Works perfectly In great shape  \\n296519  Gorgeous floral Nicole dress. Textured black w...  \\n296520  NEW W TAGS 3 pair BOYSHORTs Medium ( 3 for 25)...  \\n296521              Dust Bag Included These are a beauty!  \\n296522  Size XL but fits like a large. Brand new. Very...  \\n296523  Brand new in box with logos on bracelet. Made ...  \\n296524  Color Black on black. Toddler size 7. Great co...  \\n296525  Versatile- wear on a casual or\\xa0work\\xa0day! Side\\xa0...  \\n296526  \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" Paw Patrol is a ...  \\n296527  FREE SHIPPING PRICE IS FIRM CUTE SEXY VS PINK ...  \\n296528                                Brand new black hat  \\n296529  Bandolino Madia Dress Sandal - Size 7 - Black ...  \\n296530  Pittsburgh Steelers twisted headband A lot of ...  \\n296531  Women\\'s Small Under Armour Hoodie In great con...  \\n296532                         Lot of 7 blue accessories!  \\n296533                          Elvira In good condition.  \\n296534  Classic relaxed bootcut. Has some stretch. Exc...  \\n296535  Top is size large. Bottom is size small. Willi...  \\n296536                                  Size small/medium  \\n...                                                   ...  \\n889491  ➡ NOT A DUPLICATED LISTING ⬅ Three Packs Of An...  \\n889492  Handmade by me, 12mm, faux Druzy bead on gold ...  \\n889493  Gun case for iphone 5/5s Got some damage on it...  \\n889494  Size 8.5 in Women Retail Price [rm]+Tax BRAND ...  \\n889495  ✨Anastacia Beverly Hills, Medium to Tan✨ Retai...  \\n889496  This is a size small muscle style tank top. Ha...  \\n889497                 Both are new with tag Size: Medium  \\n889498  Very stylish crochet too perfect for summer an...  \\n889499                                      Free Shipping  \\n889500  NEW with tags size 4T Smoke free home Puffy ve...  \\n889501          Jeffrey Campbell size 9.5 brown tan shoes  \\n889502  From F21. Never really wore it. I love the ope...  \\n889503              Its in great condition battery\\'s fine  \\n889504                                 No description yet  \\n889505  Excellent condition Nike free 5.0 shoes size 6...  \\n889506  Includes 3 never used compacts! Great for priz...  \\n889507  Two Victoria Secret instant glow bronzing mous...  \\n889508                             Size 10 8/10 condition  \\n889509  -holographic highlight shades only swatched on...  \\n889510                                           HOLD ***  \\n889511  4 LIFE IMPROVEMENT BOOKS BUNDLE. All in great ...  \\n889512  Makeup remover, foundation and roll on perfume...  \\n889513  Learn crochet. A book to teach you the basics ...  \\n889514  Hand washed and laid flat to dry (needs ironed...  \\n889515  This Fitbit Charge 2 Band is a size SMALL. SIZ...  \\n889516  Brand new with tags size xl Ariat dress. Breez...  \\n889517  3 bottles damage eraser 1 Brazilian smooth 1 s...  \\n889518  good condition scratched from the front a bit,...  \\n889519  New! Teenage Mutant Ninja Turtles Raphael cost...  \\n889520                                 No description yet  \\n\\n[593014 rows x 6 columns], \\'y\\': array([ 2.07944154,  2.63905733,  3.61091791, ...,  3.40119738,\\n        2.77258872,  2.7080502 ]), \\'**\\': {}}: PicklingError(\"Can\\'t pickle <function <lambda> at 0x111756f28>: it\\'s not found as __main__.<lambda>\",)')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_getattribute\u001b[0;34m(obj, name)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module '__main__' has no attribute '<lambda>'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_global\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0mobj2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_getattribute\u001b[0;34m(obj, name)\u001b[0m\n\u001b[1;32m    271\u001b[0m             raise AttributeError(\"Can't get attribute {!r} on {!r}\"\n\u001b[0;32m--> 272\u001b[0;31m                                  .format(name, obj))\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute '<lambda>' on <module '__main__'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-98b32d67a435>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Finally, we start training the pipeline with GridSearchCV, using the .fit() method and training set:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mpl3grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# We need to delete the temporary folder before we exit the training task to allow the memory back to system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \"\"\"\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    212\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;31m# Compare the function code with the previous to see if the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# function code has changed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margument_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_output_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0moutput_pickle_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m_get_output_dir\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \"\"\"\n\u001b[0;32m--> 585\u001b[0;31m         \u001b[0margument_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_argument_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m         output_dir = os.path.join(self._get_func_dir(self.func),\n\u001b[1;32m    587\u001b[0m                                   argument_hash)\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m_get_argument_hash\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m         return hashing.hash(filter_args(self.func, self.ignore,\n\u001b[1;32m    578\u001b[0m                                          args, kwargs),\n\u001b[0;32m--> 579\u001b[0;31m                              coerce_mmap=(self.mmap_mode is not None))\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_output_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36mhash\u001b[0;34m(obj, hash_name, coerce_mmap)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mhasher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHasher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhash_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhash_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36mhash\u001b[0;34m(self, obj, return_digest)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_digest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'PicklingError while hashing %r: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'HASHED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mHasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MyHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# This fails on python 3 when keys are unorderable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;31m# but we keep it in a try as it's faster.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;31m# If keys are unorderable, sorting them using their hash. This is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'HASHED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mHasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MyHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'HASHED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mHasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MyHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# This fails on python 3 when keys are unorderable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;31m# but we keep it in a try as it's faster.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;31m# If keys are unorderable, sorting them using their hash. This is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'HASHED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mHasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MyHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    803\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMARK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPENDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'HASHED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mHasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MyHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_tuple\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m             \u001b[0;31m# Subtle.  Same as in the big comment below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'HASHED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mHasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MyHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'HASHED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mHasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MyHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# This fails on python 3 when keys are unorderable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;31m# but we keep it in a try as it's faster.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;31m# If keys are unorderable, sorting them using their hash. This is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'HASHED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mHasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MyHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    803\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMARK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPENDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'HASHED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mHasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MyHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_tuple\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m             \u001b[0;31m# Subtle.  Same as in the big comment below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'HASHED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mHasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MyHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'HASHED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mHasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MyHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# This fails on python 3 when keys are unorderable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;31m# but we keep it in a try as it's faster.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;31m# If keys are unorderable, sorting them using their hash. This is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'HASHED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mHasher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/hashing.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MyHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_global\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    920\u001b[0m             raise PicklingError(\n\u001b[1;32m    921\u001b[0m                 \u001b[0;34m\"Can't pickle %r: it's not found as %s.%s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 (obj, module_name, name))\n\u001b[0m\u001b[1;32m    923\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mobj2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: (\"Can't pickle <function <lambda> at 0x111756f28>: it's not found as __main__.<lambda>\", 'PicklingError while hashing {\\'transformer\\': FeatureUnion(n_jobs=1,\\n       transformer_list=[(\\'numeric_subpipeline\\', Pipeline(memory=None,\\n     steps=[(\\'parser\\', FunctionTransformer(accept_sparse=False,\\n          func=<function <lambda> at 0x111756f28>, inv_kw_args=None,\\n          inverse_func=None, kw_args=None, pass_y=\\'deprecated\\',\\n          validate=False)), (\\'imputer\\',...izer=None)), (\\'dim_red1\\', SelectKBest(k=200, score_func=<function f_regression at 0x1036cd6a8>))]))],\\n       transformer_weights=None), \\'weight\\': None, \\'X\\':                                              name  item_condition_id  \\\\\\n296507         Fluffy pom pom knit infinity scarf                  4   \\n296508            Flannel Abercrombie button down                  2   \\n296509                            RAE DUNN BUNDLE                  1   \\n296510                          Baby girl blanket                  1   \\n296511                 New lularoe os cool pandas                  1   \\n296512                     Nike Air Presto (wmns)                  2   \\n296513                      7y nike nike free 5.0                  3   \\n296514    Bundle 2pairs of jeans and I pair chino                  1   \\n296515        LuLaRoe OS raccoons nwt unicorn HTF                  1   \\n296516                              VS Pink socks                  3   \\n296517                               Cactus Decal                  1   \\n296518                              Beats Mix Pro                  3   \\n296519                   NWT Lularoe Nicole small                  1   \\n296520                            VS PINK M Lexie                  1   \\n296521               Kendra Scoot Bexley Earrings                  1   \\n296522                            Women\\'s Sweater                  1   \\n296523                      Cartier Love Bracelet                  1   \\n296524                         Black toddler vans                  3   \\n296525       White House Black Market Skirt White                  3   \\n296526               2 shirts + makeup bag bundle                  3   \\n296527   SALE.!! 2 LARGE PINK BOYSHORTS FREE SHIP                  1   \\n296528                      Victoria\\'s Secret hat                  1   \\n296529        Bandolino Madia Dress Sandals Black                  2   \\n296530               Pittsburgh Steelers Headband                  1   \\n296531                         Under Amour Hoodie                  3   \\n296532     Littlest pet shop clothing accessories                  3   \\n296533                           Funko pop Elvira                  1   \\n296534     Levies women\\'s 10 Long classic bootcut                  3   \\n296535      High wasted swimsuit READ DESCRIPTION                  1   \\n296536                    Harry Potter adult robe                  3   \\n...                                           ...                ...   \\n889491        Gain Laundry & Colgate & Angel Soft                  1   \\n889492     Bright pink iridescent faux druzy ring                  1   \\n889493                          Iphone 5 gun case                  4   \\n889494         NWT! Vans 1.5 (Mesh) Eclipse/White                  1   \\n889495   ✨Anastacia Beverly Hills, Medium to Tan✨                  3   \\n889496    Livin free eagle texas graphic mesh tee                  2   \\n889497                    Bundle of 2 Summer Tops                  1   \\n889498           Festival Crochet Halter Crop Top                  3   \\n889499  SUPERSALE APPLE iPhone 6 Charger [rm]each                  1   \\n889500     NWT Urban Republic boys hoodie coat 4T                  1   \\n889501                Vintage by Jeffrey Campbell                  3   \\n889502                              Nude Bodysuit                  2   \\n889503                          Men\\'s Nixon watch                  3   \\n889504                                    2 Black                  2   \\n889505   Nike air shoes size 6C toddler baby girl                  2   \\n889506                          Mary Kay Compacts                  1   \\n889507                         VS bronzing mousse                  1   \\n889508                      Retro 5s sons of mars                  3   \\n889509    Kat Von D Holographic Alchemist Palette                  2   \\n889510                  Earrings and necklace set                  1   \\n889511            4 LIFE IMPROVEMENT BOOKS BUNDLE                  3   \\n889512               3 pc mini Chanel makeup pack                  1   \\n889513                              Learn crochet                  3   \\n889514          Reserved for BUKA - WDW Purple SE                  4   \\n889515          Fitbit Charge 2 Band - Light Pink                  1   \\n889516                          Cute summer dress                  1   \\n889517                Garnier Fructis Conditioner                  1   \\n889518                                     Bundle                  3   \\n889519            TMNT Raphael Costume (8) f/ship                  1   \\n889520                  Medium one piece swimsuit                  1   \\n\\n                                            category_name  \\\\\\n296507          Women/Women\\'s Accessories/Scarves & Wraps   \\n296508             Women/Tops & Blouses/Button Down Shirt   \\n296509     Home/Kitchen & Dining/Coffee & Tea Accessories   \\n296510                               Kids/Nursery/Bedding   \\n296511     Women/Athletic Apparel/Pants, Tights, Leggings   \\n296512                               Women/Shoes/Athletic   \\n296513                               Women/Shoes/Athletic   \\n296514                             Men/Jeans/Slim, Skinny   \\n296515                               Women/Jeans/Leggings   \\n296516                       Women/Athletic Apparel/Socks   \\n296517                       Handmade/Paper Goods/Sticker   \\n296518    Electronics/TV, Audio & Surveillance/Headphones   \\n296519                          Women/Dresses/Knee-Length   \\n296520                            Women/Underwear/Panties   \\n296521                             Women/Jewelry/Earrings   \\n296522                            Women/Sweaters/Cardigan   \\n296523                            Women/Jewelry/Bracelets   \\n296524                              Kids/Boys 2T-5T/Shoes   \\n296525                      Women/Skirts/Straight, Pencil   \\n296526                    Kids/Boys 2T-5T/Tops & T-Shirts   \\n296527                            Women/Underwear/Panties   \\n296528                     Women/Women\\'s Accessories/Hats   \\n296529                                Women/Shoes/Sandals   \\n296530                     Sports & Outdoors/Fan Shop/NFL   \\n296531                              Women/Sweaters/Hooded   \\n296532                      Kids/Toys/Dolls & Accessories   \\n296533           Vintage & Collectibles/Toy/Action Figure   \\n296534                               Women/Jeans/Boot Cut   \\n296535                           Women/Swimwear/Two-Piece   \\n296536                                  Other/Other/Other   \\n...                                                   ...   \\n889491          Home/Cleaning Supplies/Household Cleaners   \\n889492                                Women/Jewelry/Rings   \\n889493  Electronics/Cell Phones & Accessories/Cases, C...   \\n889494                       Women/Shoes/Fashion Sneakers   \\n889495                      Beauty/Makeup/Makeup Palettes   \\n889496                    Women/Tops & Blouses/Tank, Cami   \\n889497                    Women/Tops & Blouses/Tank, Cami   \\n889498                        Women/Tops & Blouses/Halter   \\n889499  Electronics/Cell Phones & Accessories/Cables &...   \\n889500                     Kids/Boys (4+)/Coats & Jackets   \\n889501                          Women/Shoes/Mules & Clogs   \\n889502                           Women/Swimwear/One-Piece   \\n889503                      Men/Men\\'s Accessories/Watches   \\n889504                        Women/Tops & Blouses/Blouse   \\n889505                             Kids/Girls 2T-5T/Shoes   \\n889506                                 Beauty/Makeup/Eyes   \\n889507                             Beauty/Fragrance/Women   \\n889508                                 Men/Shoes/Athletic   \\n889509                      Beauty/Makeup/Makeup Palettes   \\n889510                            Women/Jewelry/Necklaces   \\n889511                  Vintage & Collectibles/Book/Other   \\n889512  Beauty/Tools & Accessories/Makeup Brushes & Tools   \\n889513                          Handmade/Patterns/Crochet   \\n889514                        Kids/Girls 0-24 Mos/Dresses   \\n889515      Sports & Outdoors/Exercise/Fitness technology   \\n889516                     Women/Dresses/Above Knee, Mini   \\n889517        Beauty/Hair Care/Shampoo & Conditioner Sets   \\n889518                             Kids/Girls 2T-5T/Shoes   \\n889519                  Kids/Toys/Dress Up & Pretend Play   \\n889520                           Women/Swimwear/One-Piece   \\n\\n                      brand_name  shipping  \\\\\\n296507                       NaN         0   \\n296508       Abercrombie & Fitch         0   \\n296509                  Rae Dunn         0   \\n296510                       NaN         1   \\n296511                       NaN         1   \\n296512                      Nike         1   \\n296513                      Nike         0   \\n296514                       NaN         1   \\n296515                       NaN         0   \\n296516                      PINK         1   \\n296517                       NaN         1   \\n296518          Beats by Dr. Dre         0   \\n296519                   LuLaRoe         0   \\n296520         Victoria\\'s Secret         1   \\n296521              Kendra Scott         1   \\n296522            New Directions         0   \\n296523                   Cartier         0   \\n296524                       NaN         0   \\n296525  White House Black Market         0   \\n296526                       NaN         0   \\n296527                      PINK         1   \\n296528         Victoria\\'s Secret         0   \\n296529                 Bandolino         0   \\n296530                       NaN         1   \\n296531              Under Armour         1   \\n296532                    Hasbro         0   \\n296533                     Funko         0   \\n296534                   Levi\\'s®         0   \\n296535                       NaN         0   \\n296536                       NaN         1   \\n...                          ...       ...   \\n889491                       NaN         0   \\n889492                       NaN         1   \\n889493                       NaN         1   \\n889494                      VANS         1   \\n889495                   Sephora         1   \\n889496                FOREVER 21         0   \\n889497                       NaN         1   \\n889498                       NaN         0   \\n889499                     Apple         1   \\n889500                   Arizona         0   \\n889501          Jeffrey Campbell         0   \\n889502                FOREVER 21         0   \\n889503                     Nixon         0   \\n889504                   Express         0   \\n889505                      Nike         0   \\n889506                  Mary Kay         0   \\n889507         Victoria\\'s Secret         1   \\n889508                    Jordan         0   \\n889509                 Kat Von D         0   \\n889510                       NaN         1   \\n889511                       NaN         0   \\n889512                    Chanel         1   \\n889513                       NaN         0   \\n889514                       NaN         1   \\n889515                       NaN         1   \\n889516                     Ariat         0   \\n889517                   Garnier         0   \\n889518                  Gymboree         0   \\n889519                       NaN         1   \\n889520                       NaN         1   \\n\\n                                         item_description  \\n296507  Cute cream colored infinity scarf with knit po...  \\n296508  Flannel shirt by Abercrombie. Size large. Supe...  \\n296509  PRICE IS FOR ALL THREE // CANT BE BOUGHT SEPAR...  \\n296510  I can take off the hanger if you would like ju...  \\n296511  New lularoe one size cool pandas with glasses ...  \\n296512  Size 7, brand new never worn! Ended up finding...  \\n296513  Women size 9 Good conditions Fast shipping No ...  \\n296514  Reserved for Mess_cx I pair of Bullhead light ...  \\n296515  LuLaRoe OS size raccoon leggings. Red and blue...  \\n296516  EUC These have been washed, I attempted to wea...  \\n296517      4 \" Decal Yeti decal Monogram decal Car decal  \\n296518                     Works perfectly In great shape  \\n296519  Gorgeous floral Nicole dress. Textured black w...  \\n296520  NEW W TAGS 3 pair BOYSHORTs Medium ( 3 for 25)...  \\n296521              Dust Bag Included These are a beauty!  \\n296522  Size XL but fits like a large. Brand new. Very...  \\n296523  Brand new in box with logos on bracelet. Made ...  \\n296524  Color Black on black. Toddler size 7. Great co...  \\n296525  Versatile- wear on a casual or\\xa0work\\xa0day! Side\\xa0...  \\n296526  \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" Paw Patrol is a ...  \\n296527  FREE SHIPPING PRICE IS FIRM CUTE SEXY VS PINK ...  \\n296528                                Brand new black hat  \\n296529  Bandolino Madia Dress Sandal - Size 7 - Black ...  \\n296530  Pittsburgh Steelers twisted headband A lot of ...  \\n296531  Women\\'s Small Under Armour Hoodie In great con...  \\n296532                         Lot of 7 blue accessories!  \\n296533                          Elvira In good condition.  \\n296534  Classic relaxed bootcut. Has some stretch. Exc...  \\n296535  Top is size large. Bottom is size small. Willi...  \\n296536                                  Size small/medium  \\n...                                                   ...  \\n889491  ➡ NOT A DUPLICATED LISTING ⬅ Three Packs Of An...  \\n889492  Handmade by me, 12mm, faux Druzy bead on gold ...  \\n889493  Gun case for iphone 5/5s Got some damage on it...  \\n889494  Size 8.5 in Women Retail Price [rm]+Tax BRAND ...  \\n889495  ✨Anastacia Beverly Hills, Medium to Tan✨ Retai...  \\n889496  This is a size small muscle style tank top. Ha...  \\n889497                 Both are new with tag Size: Medium  \\n889498  Very stylish crochet too perfect for summer an...  \\n889499                                      Free Shipping  \\n889500  NEW with tags size 4T Smoke free home Puffy ve...  \\n889501          Jeffrey Campbell size 9.5 brown tan shoes  \\n889502  From F21. Never really wore it. I love the ope...  \\n889503              Its in great condition battery\\'s fine  \\n889504                                 No description yet  \\n889505  Excellent condition Nike free 5.0 shoes size 6...  \\n889506  Includes 3 never used compacts! Great for priz...  \\n889507  Two Victoria Secret instant glow bronzing mous...  \\n889508                             Size 10 8/10 condition  \\n889509  -holographic highlight shades only swatched on...  \\n889510                                           HOLD ***  \\n889511  4 LIFE IMPROVEMENT BOOKS BUNDLE. All in great ...  \\n889512  Makeup remover, foundation and roll on perfume...  \\n889513  Learn crochet. A book to teach you the basics ...  \\n889514  Hand washed and laid flat to dry (needs ironed...  \\n889515  This Fitbit Charge 2 Band is a size SMALL. SIZ...  \\n889516  Brand new with tags size xl Ariat dress. Breez...  \\n889517  3 bottles damage eraser 1 Brazilian smooth 1 s...  \\n889518  good condition scratched from the front a bit,...  \\n889519  New! Teenage Mutant Ninja Turtles Raphael cost...  \\n889520                                 No description yet  \\n\\n[593014 rows x 6 columns], \\'y\\': array([ 2.07944154,  2.63905733,  3.61091791, ...,  3.40119738,\\n        2.77258872,  2.7080502 ]), \\'**\\': {}}: PicklingError(\"Can\\'t pickle <function <lambda> at 0x111756f28>: it\\'s not found as __main__.<lambda>\",)')"
     ]
    }
   ],
   "source": [
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from sklearn.externals.joblib import Memory\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# We first create a temporary folder to store the transformers of our pipeline\n",
    "temp_folder = mkdtemp()\n",
    "memory = Memory(cachedir= temp_folder, verbose= 10) # Create our memory \n",
    "\n",
    "# Next we need to redefine our pipeline3 with a memory argument to pass the memory we created\n",
    "memorized_pipeline3 = Pipeline(steps=[\n",
    "    \n",
    "    (\"union\",FeatureUnion(        #Note that FeatureUnion() accepts list of tuples, the first half of each tuple is the name of the transformer\n",
    "        \n",
    "        transformer_list = [\n",
    "            \n",
    "            (\"numeric_subpipeline\", Pipeline([        #Note we have subpipeline branches inside the main pipeline\n",
    "                \n",
    "                (\"parser\",get_numeric_data), # Step1: parse the numeric data (note how we avoid () when using FunctionTransformer objects)\n",
    "                (\"imputer\",Imputer()), # Step2: impute missing values\n",
    "            \n",
    "            ])), # Branching point of the FeatureUnion\n",
    "            \n",
    "            (\"text_subpipeline\",Pipeline([\n",
    "            \n",
    "                (\"parser\",get_text_data), # Step1: parse the text data \n",
    "                (\"tokenizer\",HashingVectorizer(token_pattern= TOKENS_ALPHANUMERIC,\n",
    "                                             stop_words = \"english\",# We will remove English stop words before tokenization\n",
    "                                             ngram_range = (1,3),\n",
    "                                             non_negative=True, norm=None, binary=False  \n",
    "                                            )), # Step2: use CountVectorizer for automated tokenization and feature extraction\n",
    "                                            ('dim_red1', SelectKBest(f_regression, 300)) # Step3: use dimension reduction to select 300 best features\n",
    "                \n",
    "            ]))\n",
    "        ]\n",
    "    \n",
    "    )),# Branching point to the main pipeline: at this point all fearures are numeric\n",
    "    \n",
    "    (\"int\", SparseInteractions(degree=2)), # Add polynomial interaction terms \n",
    "    (\"scaler\",MaxAbsScaler()), # Scale the features\n",
    "    (\"reg\",Ridge(alpha = 0.5)) # Add the RidgeRegression step using alpha = 0.5\n",
    "    \n",
    "], memory = memory) \n",
    "\n",
    "\n",
    "# Now we are using the catched (memorized) pipeline for GridSearchCV, \n",
    "    # using 3-fold cross-validation\n",
    "    # using the parameter grid space we defined above\n",
    "    \n",
    "pl3grid = GridSearchCV(memorized_pipeline3, cv = 3, n_jobs= 1, param_grid= param_grid,scoring='neg_mean_squared_error')\n",
    "\n",
    "# Finally, we start training the pipeline with GridSearchCV, using the .fit() method and training set:\n",
    "pl3grid.fit(X_train,y_train)\n",
    "\n",
    "# We need to delete the temporary folder before we exit the training task to allow the memory back to system\n",
    "rmtree(temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [https://github.com/scikit-learn/scikit-learn/issues/1645] this discussion it appears that the serialization we attempt to make uses pickle, which is not compatible with lambda functions. We notice that the lambda functions appear in our pipeline at the custom utility functions we wrote. Therefore, we need to rewrite these utility functions to make them compatible with the serialization process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_text_processer_nolambda(df,text_columns = Text_features):\n",
    "    \"\"\"\"A function that will merge/join all text in a given row to make it ready for tokenization. \n",
    "    - This function should take care of converting missing values to empty strings. \n",
    "    - It should also convert the text to lowercase.\n",
    "    df= pandas dataframe\n",
    "    text_columns = names of the text features in df\n",
    "    \"\"\" \n",
    "    # Select only non-text columns that are in the df\n",
    "    text_data = df[text_columns]\n",
    "    \n",
    "    # Fill the missing values in text_data using empty strings\n",
    "    text_data.fillna(\"\",inplace=True)\n",
    "    \n",
    "    # Join all the strings in a given row to make a vector\n",
    "    # text_vector = text_data.apply(lambda x: \" \".join(x), axis = 1)\n",
    "    text_vector = []\n",
    "    for index,rows in text_data.iterrows():\n",
    "        text_item = \" \".join(rows).lower()\n",
    "        text_vector.append(text_item)\n",
    "\n",
    "    # return text_vector as pd.Series object to enter the tokenization pipeline\n",
    "    return pd.Series(text_vector) \n",
    "\n",
    "def column_numeric_processer_nolambda(df,numeric_columns = Numeric_features):\n",
    "    return df[numeric_columns]\n",
    "\n",
    "#############################################################################\n",
    "# Utility functions to parse text and numeric features\n",
    "get_numeric_data = FunctionTransformer(func = column_numeric_processer_nolambda, validate=False) \n",
    "get_text_data = FunctionTransformer(column_text_processer_nolambda,validate=False) # Note how we avoid putting any arguments into column_text_processer\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's redefine our entire data reading and pre-processing pipeline with these custom functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from SparseInteractions import * #Load SparseInteractions as a module since it was saved into working directory as SparseInteractions.py\n",
    "\n",
    "#############################################################################\n",
    "# Re-read the training and hold out data\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\", header=None, names= [\"price\"])\n",
    "y_train = y_train.price.values\n",
    "\n",
    "X_holdout = pd.read_csv(\"X_holdout.csv\")\n",
    "y_holdout = pd.read_csv(\"y_holdout.csv\", header=None, names= [\"price\"])\n",
    "y_holdout = y_holdout.price.values\n",
    "\n",
    "#############################################################################\n",
    "# Re-read the pickled feature names\n",
    "import pickle\n",
    "with open(\"Numeric_features.pkl\", 'rb') as f:\n",
    "    Numeric_features = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "with open(\"Text_features.pkl\", 'rb') as f:\n",
    "    Text_features = pickle.load(f)\n",
    "f.close()\n",
    "#############################################################################\n",
    "# Custom utility functions to parse out numeric and text data\n",
    "\n",
    "def column_text_processer_nolambda(df,text_columns = Text_features):\n",
    "    \"\"\"\"A function that will merge/join all text in a given row to make it ready for tokenization. \n",
    "    - This function should take care of converting missing values to empty strings. \n",
    "    - It should also convert the text to lowercase.\n",
    "    df= pandas dataframe\n",
    "    text_columns = names of the text features in df\n",
    "    \"\"\" \n",
    "    # Select only non-text columns that are in the df\n",
    "    text_data = df[text_columns]\n",
    "    \n",
    "    # Fill the missing values in text_data using empty strings\n",
    "    text_data.fillna(\"\",inplace=True)\n",
    "    \n",
    "    # Join all the strings in a given row to make a vector\n",
    "    # text_vector = text_data.apply(lambda x: \" \".join(x), axis = 1)\n",
    "    text_vector = []\n",
    "    for index,rows in text_data.iterrows():\n",
    "        text_item = \" \".join(rows).lower()\n",
    "        text_vector.append(text_item)\n",
    "\n",
    "    # return text_vector as pd.Series object to enter the tokenization pipeline\n",
    "    return pd.Series(text_vector) \n",
    "\n",
    "def column_numeric_processer_nolambda(df,numeric_columns = Numeric_features):\n",
    "    return df[numeric_columns]\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler, Imputer, FunctionTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#############################################################################\n",
    "# FunctionTransformer wrapper of utility functions to parse text and numeric features\n",
    "get_numeric_data = FunctionTransformer(func = column_numeric_processer_nolambda, validate=False) \n",
    "get_text_data = FunctionTransformer(column_text_processer_nolambda,validate=False) # Note how we avoid putting any arguments into column_text_processer  \n",
    "#############################################################################\n",
    "\n",
    "#############################################################################\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'   #Note this regex will match either a whitespace or a punctuation to tokenize the string vector on these preferences  \n",
    "\n",
    "#############################################################################\n",
    "# Define f_regression for feature selection to convert center = False default\n",
    "def f_regression(X,Y):\n",
    "    import sklearn\n",
    "    return sklearn.feature_selection.f_regression(X,Y,center = False) # default is center = True\n",
    "\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we re-define our memorized pipeline together with hyperparameter search space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "[joblib] Attempting to do parallel computing without protecting your import on a system that does not support forking. To use parallel-computing in a script, you must protect your main loop using \"if __name__ == '__main__'\". Please see the joblib documentation on Parallel for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-bd02802a1bc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# Finally, we start training the pipeline with GridSearchCV, using the .fit() method and training set:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mpl3grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aborting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_effective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_initialize_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n\u001b[0;32m--> 547\u001b[0;31m                                              **self._backend_args)\n\u001b[0m\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_timeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                 warnings.warn(\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mconfigure\u001b[0;34m(self, n_jobs, parallel, **backend_args)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malready_forked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             raise ImportError(\n\u001b[0;32m--> 305\u001b[0;31m                 \u001b[0;34m'[joblib] Attempting to do parallel computing '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m                 \u001b[0;34m'without protecting your import on a system that does '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0;34m'not support forking. To use parallel-computing in a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: [joblib] Attempting to do parallel computing without protecting your import on a system that does not support forking. To use parallel-computing in a script, you must protect your main loop using \"if __name__ == '__main__'\". Please see the joblib documentation on Parallel for more information"
     ]
    }
   ],
   "source": [
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from sklearn.externals.joblib import Memory\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# We first create a temporary folder to store the transformers of our pipeline\n",
    "temp_folder = mkdtemp()\n",
    "memory = Memory(cachedir= temp_folder, verbose= 10) # Create our memory \n",
    "\n",
    "\n",
    "# Next we need to redefine our pipeline3 with a memory argument to pass the memory we created\n",
    "memorized_pipeline3 = Pipeline(steps=[\n",
    "    \n",
    "    (\"union\",FeatureUnion(        #Note that FeatureUnion() accepts list of tuples, the first half of each tuple is the name of the transformer\n",
    "        \n",
    "        transformer_list = [\n",
    "            \n",
    "            (\"numeric_subpipeline\", Pipeline([        #Note we have subpipeline branches inside the main pipeline\n",
    "                \n",
    "                (\"parser\",get_numeric_data), # Step1: parse the numeric data (note how we avoid () when using FunctionTransformer objects)\n",
    "                (\"imputer\",Imputer()), # Step2: impute missing values\n",
    "            \n",
    "            ])), # Branching point of the FeatureUnion\n",
    "            \n",
    "            (\"text_subpipeline\",Pipeline([\n",
    "            \n",
    "                (\"parser\",get_text_data), # Step1: parse the text data \n",
    "                (\"tokenizer\",HashingVectorizer(token_pattern= TOKENS_ALPHANUMERIC,\n",
    "                                             stop_words = \"english\",# We will remove English stop words before tokenization\n",
    "                                             ngram_range = (1,3),\n",
    "                                             non_negative=True, norm=None, binary=False  \n",
    "                                            )), # Step2: use CountVectorizer for automated tokenization and feature extraction\n",
    "                                            ('dim_red1', SelectKBest(f_regression, 300)) # Step3: use dimension reduction to select 300 best features\n",
    "                \n",
    "            ]))\n",
    "        ]\n",
    "    \n",
    "    )),# Branching point to the main pipeline: at this point all fearures are numeric\n",
    "    \n",
    "    (\"int\", SparseInteractions(degree=2)), # Add polynomial interaction terms \n",
    "    (\"scaler\",MaxAbsScaler()), # Scale the features\n",
    "    (\"reg\",Ridge(alpha = 0.5)) # Add the RidgeRegression step using alpha = 0.5\n",
    "    \n",
    "], memory = memory) \n",
    "\n",
    "# Our hyperparameter grid\n",
    "param_grid = {\n",
    "    'reg__alpha': np.linspace(1,0,10),\n",
    "    'union__text_subpipeline__dim_red1__k': [200,300,400],\n",
    "    'union__text_subpipeline__tokenizer__ngram_range': [(1,3),(1,4)], # We will tokenize for up to 4-grams \n",
    "    'int__degree': [2,3] # We will add up to the third polymonial degree interactions \n",
    "}\n",
    "\n",
    "\n",
    "# Now we are using the catched (memorized) pipeline for GridSearchCV, \n",
    "    # using 3-fold cross-validation\n",
    "    # using the parameter grid space we defined above\n",
    "\n",
    "  \n",
    "pl3grid = GridSearchCV(memorized_pipeline3, \n",
    "                       cv = 3, \n",
    "                       n_jobs= 1, \n",
    "                       param_grid= param_grid,\n",
    "                       scoring='neg_mean_squared_error')\n",
    "\n",
    "\n",
    "# Finally, we start training the pipeline with GridSearchCV, using the .fit() method and training set:\n",
    "pl3grid.fit(X_train,y_train)\n",
    "\n",
    "# We need to delete the temporary folder before we exit the training task to allow the memory back to system\n",
    "rmtree(temp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import cpu_count\n",
    "cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our take home messages:\n",
    "\n",
    "1. Using cache option to memorize steps with large data sets and a complex pipeline is not feasible. Computer crashes.\n",
    "2. The n_jobs = -1 parallelization using joblib interface of sklearn is not functional. The error seems to persist as of March 2018.\n",
    "\n",
    "Therefore, our next solution could be using Dask package or spark-sklearn for paralelization. They appear to have their own problems though.\n",
    "\n",
    "Until we have a good understanding the nature of these problems, we should avoid ambitious hyperparameter optimization using GridSearchCV, and tune few parameters at a given time instead.\n",
    "\n",
    "# Searching a better Ridge pipeline using RandomizedSearchCV\n",
    "\n",
    "Yes, we realized it is not feasible to use an exhaustive GridSearchCV for hyperparameter optimization given the size of the training data and our limited computational power. However, we should still give a try to RandomSearchCV, where we can test 10 or 20 iterations to randomly pick combinations of parameters from our hyperparameter bucket and see if we can get a model with better performance. This is in a way a matter of luck and waiting game, but nothing should stop us from trying, give there is a possiblity of finding a slighly better performing model. \n",
    "\n",
    "First we get our Ridge pipeline and hyperparameter space as usual:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from SparseInteractions import * #Load SparseInteractions as a module since it was saved into working directory as SparseInteractions.py\n",
    "\n",
    "#############################################################################\n",
    "# Re-read the training and hold out data\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\", header=None, names= [\"price\"])\n",
    "y_train = y_train.price.values\n",
    "\n",
    "X_holdout = pd.read_csv(\"X_holdout.csv\")\n",
    "y_holdout = pd.read_csv(\"y_holdout.csv\", header=None, names= [\"price\"])\n",
    "y_holdout = y_holdout.price.values\n",
    "\n",
    "#############################################################################\n",
    "# Re-read the pickled feature names\n",
    "import pickle\n",
    "with open(\"Numeric_features.pkl\", 'rb') as f:\n",
    "    Numeric_features = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "with open(\"Text_features.pkl\", 'rb') as f:\n",
    "    Text_features = pickle.load(f)\n",
    "f.close()\n",
    "#############################################################################\n",
    "# Custom utility functions to parse out numeric and text data\n",
    "\n",
    "def column_text_processer_nolambda(df,text_columns = Text_features):\n",
    "    \"\"\"\"A function that will merge/join all text in a given row to make it ready for tokenization. \n",
    "    - This function should take care of converting missing values to empty strings. \n",
    "    - It should also convert the text to lowercase.\n",
    "    df= pandas dataframe\n",
    "    text_columns = names of the text features in df\n",
    "    \"\"\" \n",
    "    # Select only non-text columns that are in the df\n",
    "    text_data = df[text_columns]\n",
    "    \n",
    "    # Fill the missing values in text_data using empty strings\n",
    "    text_data.fillna(\"\",inplace=True)\n",
    "    \n",
    "    # Join all the strings in a given row to make a vector\n",
    "    # text_vector = text_data.apply(lambda x: \" \".join(x), axis = 1)\n",
    "    text_vector = []\n",
    "    for index,rows in text_data.iterrows():\n",
    "        text_item = \" \".join(rows).lower()\n",
    "        text_vector.append(text_item)\n",
    "\n",
    "    # return text_vector as pd.Series object to enter the tokenization pipeline\n",
    "    return pd.Series(text_vector) \n",
    "\n",
    "def column_numeric_processer_nolambda(df,numeric_columns = Numeric_features):\n",
    "    return df[numeric_columns]\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler, Imputer, FunctionTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#############################################################################\n",
    "# FunctionTransformer wrapper of utility functions to parse text and numeric features\n",
    "get_numeric_data = FunctionTransformer(func = column_numeric_processer_nolambda, validate=False) \n",
    "get_text_data = FunctionTransformer(column_text_processer_nolambda,validate=False) # Note how we avoid putting any arguments into column_text_processer  \n",
    "#############################################################################\n",
    "\n",
    "#############################################################################\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'   #Note this regex will match either a whitespace or a punctuation to tokenize the string vector on these preferences  \n",
    "\n",
    "#############################################################################\n",
    "# Define f_regression for feature selection to convert center = False default\n",
    "def f_regression(X,Y):\n",
    "    import sklearn\n",
    "    return sklearn.feature_selection.f_regression(X,Y,center = False) # default is center = True\n",
    "\n",
    "#############################################################################\n",
    "# Next we define our pipeline:\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pl3 = Pipeline([\n",
    "    \n",
    "    (\"union\",FeatureUnion(        #Note that FeatureUnion() accepts list of tuples, the first half of each tuple is the name of the transformer\n",
    "        \n",
    "        transformer_list = [\n",
    "            \n",
    "            (\"numeric_subpipeline\", Pipeline([        #Note we have subpipeline branches inside the main pipeline\n",
    "                \n",
    "                (\"parser\",get_numeric_data), # Step1: parse the numeric data (note how we avoid () when using FunctionTransformer objects)\n",
    "                (\"imputer\",Imputer()), # Step2: impute missing values\n",
    "            \n",
    "            ])), # Branching point of the FeatureUnion\n",
    "            \n",
    "            (\"text_subpipeline\",Pipeline([\n",
    "            \n",
    "                (\"parser\",get_text_data), # Step1: parse the text data \n",
    "                (\"tokenizer\",HashingVectorizer(token_pattern= TOKENS_ALPHANUMERIC,\n",
    "                                             stop_words = \"english\",# We will remove English stop words before tokenization\n",
    "                                             ngram_range = (1,3),\n",
    "                                             non_negative=True, norm=None, binary=False  \n",
    "                                            )), # Step2: use CountVectorizer for automated tokenization and feature extraction\n",
    "                                            ('dim_red1', SelectKBest(f_regression, 300)) # Step3: use dimension reduction to select 300 best features\n",
    "                \n",
    "            ]))\n",
    "        ]\n",
    "    \n",
    "    )),# Branching point to the main pipeline: at this point all fearures are numeric\n",
    "    \n",
    "    (\"int\", SparseInteractions(degree=2)), # Add polynomial interaction terms \n",
    "    (\"scaler\",MaxAbsScaler()), # Scale the features\n",
    "    (\"reg\",Ridge(alpha = 0.5)) # Add the RidgeRegression step using alpha = 0.5\n",
    "])\n",
    "\n",
    "# We define our hyperparameter grid from which we will randomly select a combination per RandomizedSeachCV iteration\n",
    "param_grid = {\n",
    "    'reg__alpha': np.linspace(1,0,10),\n",
    "    'union__text_subpipeline__dim_red1__k': [200,300,400],\n",
    "    'union__text_subpipeline__tokenizer__ngram_range': [(1,3),(1,4)], # We will tokenize for up to 4-grams \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we perform RandomizedSeachCV from the defined hyperparameter space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train start :2018-03-04 12:02:57.007283\n",
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start = datetime.datetime.now()\n",
    "print(\"train start :\"+ str(start))\n",
    "\n",
    "# Now we are using the catched (memorized) pipeline for GridSearchCV, \n",
    "    # using 2-fold cross-validation at this stage\n",
    "    # using the parameter grid space we defined above\n",
    "\n",
    "  \n",
    "pl3randomized= RandomizedSearchCV(pl3, cv = 2, param_distributions= param_grid, n_jobs= -1,\n",
    "                       scoring='neg_mean_squared_error',verbose = 1)\n",
    "\n",
    "\n",
    "# Finally, we start training the pipeline with GridSearchCV, using the .fit() method and training set:\n",
    "pl3randomized.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "import datetime\n",
    "start = datetime.datetime.now()\n",
    "print(\"train start :\"+ str(start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the pipeline using RandomForest regressor\n",
    "\n",
    "Let's try to modify our best performing pipeline 3 above by changing the regressor to RandomForest, starting with its default parameters, we will try to see if we can get a better model performance without performing any hyperparameter tuning. Note that in this case we will add another feature selection step in the pipeline before using the RandomForest model since we are not performing regularization in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from SparseInteractions import * #Load SparseInteractions as a module since it was saved into working directory as SparseInteractions.py\n",
    "\n",
    "#############################################################################\n",
    "# Re-read the training and hold out data\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\", header=None, names= [\"price\"])\n",
    "y_train = y_train.price.values\n",
    "\n",
    "X_holdout = pd.read_csv(\"X_holdout.csv\")\n",
    "y_holdout = pd.read_csv(\"y_holdout.csv\", header=None, names= [\"price\"])\n",
    "y_holdout = y_holdout.price.values\n",
    "\n",
    "#############################################################################\n",
    "# Re-read the pickled feature names\n",
    "import pickle\n",
    "with open(\"Numeric_features.pkl\", 'rb') as f:\n",
    "    Numeric_features = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "with open(\"Text_features.pkl\", 'rb') as f:\n",
    "    Text_features = pickle.load(f)\n",
    "f.close()\n",
    "#############################################################################\n",
    "\n",
    "def column_text_processer(df,text_columns = Text_features):\n",
    "    \"\"\"\"A function that will merge/join all text in a given row to make it ready for tokenization. \n",
    "    - This function should take care of converting missing values to empty strings. \n",
    "    - It should also convert the text to lowercase.\n",
    "    df= pandas dataframe\n",
    "    text_columns = names of the text features in df\n",
    "    \"\"\" \n",
    "    # Select only non-text columns that are in the df\n",
    "    text_data = df[text_columns]\n",
    "    \n",
    "    # Fill the missing values in text_data using empty strings\n",
    "    text_data.fillna(\"\",inplace=True)\n",
    "    \n",
    "    # Join all the strings in a given row to make a vector\n",
    "    text_vector = text_data.apply(lambda x: \" \".join(x), axis = 1)\n",
    "    \n",
    "    # Convert all the text to lowercase and return as pd.Series object to enter the tokenization pipeline\n",
    "    return text_vector.apply(lambda x: x.lower())  \n",
    "\n",
    "#############################################################################\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler, Imputer, FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#############################################################################\n",
    "# Utility functions to parse text and numeric features\n",
    "get_numeric_data = FunctionTransformer(func = lambda x: x[Numeric_features], validate=False) #Note x is by default the tensor that contains all features\n",
    "get_text_data = FunctionTransformer(column_text_processer,validate=False) # Note how we avoid putting any arguments into column_text_processer\n",
    "#############################################################################\n",
    "\n",
    "#############################################################################\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'   #Note this regex will match either a whitespace or a punctuation to tokenize the string vector on these preferences  \n",
    "\n",
    "#############################################################################\n",
    "# Define f_regression for feature selection to convert center = False default\n",
    "def f_regression(X,Y):\n",
    "    import sklearn\n",
    "    return sklearn.feature_selection.f_regression(X,Y,center = False) # default is center = True\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "pl4 = Pipeline([\n",
    "    \n",
    "    (\"union\",FeatureUnion(        #Note that FeatureUnion() accepts list of tuples, the first half of each tuple is the name of the transformer\n",
    "        \n",
    "        transformer_list = [\n",
    "            \n",
    "            (\"numeric_subpipeline\", Pipeline([        #Note we have subpipeline branches inside the main pipeline\n",
    "                \n",
    "                (\"parser\",get_numeric_data), # Step1: parse the numeric data (note how we avoid () when using FunctionTransformer objects)\n",
    "                (\"imputer\",Imputer()), # Step2: impute missing values\n",
    "            \n",
    "            ])), # Branching point of the FeatureUnion\n",
    "            \n",
    "            (\"text_subpipeline\",Pipeline([\n",
    "            \n",
    "                (\"parser\",get_text_data), # Step1: parse the text data \n",
    "                (\"tokenizer\",HashingVectorizer(token_pattern= TOKENS_ALPHANUMERIC,\n",
    "                                             stop_words = \"english\",# We will remove English stop words before tokenization\n",
    "                                             ngram_range = (1,3),\n",
    "                                             non_negative=True, norm=None, binary=False  \n",
    "                                            )), # Step2: use CountVectorizer for automated tokenization and feature extraction\n",
    "                                            ('dim_red1', SelectKBest(f_regression, 300)) # Step3: use dimension reduction to select 300 best features\n",
    "                \n",
    "            ]))\n",
    "        ]\n",
    "    \n",
    "    )),# Branching point to the main pipeline: at this point all fearures are numeric\n",
    "    \n",
    "    (\"int\", SparseInteractions(degree=2)), # Add polynomial interaction terms \n",
    "    (\"scaler\",MaxAbsScaler()), # Scale the features\n",
    "    ('dim_red2', SelectKBest(f_regression, 300)),\n",
    "    (\"reg\",RandomForestRegressor(n_jobs = -1, max_depth= 50)) # We start with these parameters of randomforest\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we train our pipeline using .fit method as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train start :2018-03-02 20:36:31.218289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train end :2018-03-03 16:54:33.120825\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start = datetime.datetime.now()\n",
    "print(\"train start :\"+ str(start))\n",
    "\n",
    "pl4.fit(X_train,y_train)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print(\"train end :\"+ str(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all CPU power we have (n_jobs = -1 argument in RandomForest), it took about 21 hours to train the RandomForest model even without any cross-validation with the ~800K samples and 300 features. \n",
    "\n",
    "This demonstrates that performing cross-validation or hyperparameter search with this model with this amount of training data is not feasible in our computational capacity.\n",
    "\n",
    "Let's have a look at our predictions and compare to the Ridge pipeline we trained above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48194551256309565"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred4_train = pl4.predict(X_train)\n",
    "np.sqrt(mean_squared_error(y_train,y_pred4_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like RandomForest fits into the training set better than the untuned Ridge. Let's look at the performance in the holdout set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/Users/OZANAYGUN/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.63547130284493558"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions using the holdout set\n",
    "y_pred4_holdout = pl4.predict(X_holdout)\n",
    "np.sqrt(mean_squared_error(y_holdout,y_pred4_holdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite interesting. It appears that untuned RandomForest pipeline overfits to the training set compared to untuned Ridge model. This is another nice example that a simple regularized model can perform better than a untuned complex algorithm like RandomForest.\n",
    "\n",
    "We should remember that if we had the computational power to perform hyperparameter tuning using RandomForest, we would probably find a better performing model. However, in this case computational limitations determine the most feasible model.\n",
    "\n",
    "In the next experiment, we will try to develop an intuition to use boosted trees for the same problem by employing XGboost package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
